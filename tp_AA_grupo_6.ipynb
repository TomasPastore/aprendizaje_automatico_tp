{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomasPastore/aprendizaje_automatico_tp/blob/main/tp_AA_grupo_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import timeit"
      ],
      "metadata": {
        "id": "2B-2tXYZSL3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MOkL2-DyVVUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lectura del dataset"
      ],
      "metadata": {
        "id": "Wve0SoH6-upT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn7Ktz_1R0zw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "outputId": "08f48862-4749-429a-da69-c279fad05955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     target\n",
            "0         1\n",
            "1         1\n",
            "2         1\n",
            "3         1\n",
            "5         1\n",
            "..      ...\n",
            "483       1\n",
            "490       1\n",
            "491       1\n",
            "497       1\n",
            "499       1\n",
            "\n",
            "[154 rows x 1 columns]\n",
            "\n",
            " Features\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         v000      v001      v002      v003      v004      v005       v006  \\\n",
              "0    0.203777 -7.278026  2.756077  0.412740 -0.116626  0.414236   6.218588   \n",
              "1    1.084936  0.328886  4.545345  0.678987  0.003042 -0.807901 -13.653907   \n",
              "2    0.769527 -1.213339 -1.821305 -0.816333  3.059691 -0.583517  22.961234   \n",
              "3   -0.094123 -0.567694  1.747513  0.033398  7.415277 -0.756049  -1.021780   \n",
              "4    0.116567 -1.551208  9.343513 -1.785618 -2.651805  0.955870  -0.952141   \n",
              "..        ...       ...       ...       ...       ...       ...        ...   \n",
              "495 -0.288139 -1.396761 -4.263799  0.749690  1.721721 -0.344043  19.469950   \n",
              "496  0.153794 -1.877765  0.514750  3.191452  2.515170  0.214678   1.100869   \n",
              "497  0.128327 -2.151517 -6.010139 -5.710254 -2.606002 -0.326701  -3.537265   \n",
              "498  0.907801  2.899501 -2.170869  1.386165  4.658550  0.172423   2.034290   \n",
              "499  0.173000  1.544216  7.862991  2.611334 -3.852684 -0.453429  30.162525   \n",
              "\n",
              "         v007      v008      v009  ...       v190       v191      v192  \\\n",
              "0    0.018764  0.209555  0.005660  ...  -8.551783  -5.323863  2.004479   \n",
              "1   -0.654958 -0.860854 -1.017529  ...   1.195129 -20.574463  0.119288   \n",
              "2   -1.034725 -0.039125  0.983415  ...   2.926464  14.608653 -0.456923   \n",
              "3   -0.662921 -0.671345 -0.159661  ...   4.750111  21.559404  0.188952   \n",
              "4   -0.854849 -0.679621  0.682699  ...   0.364826  24.729498 -0.585663   \n",
              "..        ...       ...       ...  ...        ...        ...       ...   \n",
              "495  0.662457  0.557387 -0.190842  ...   1.589264  17.684302 -1.333075   \n",
              "496 -0.641812 -0.192485  2.340703  ...  -0.849789 -12.417970  0.906713   \n",
              "497 -0.786013 -0.985565  0.120138  ... -10.669278  -7.494708  0.520567   \n",
              "498  0.563519 -1.294684  0.853006  ...   0.691517 -18.558853  1.667956   \n",
              "499 -0.319517 -0.718359  1.447191  ...  -5.883870  28.225737  0.104841   \n",
              "\n",
              "         v193      v194      v195      v196      v197      v198      v199  \n",
              "0   -0.065859 -0.877748  0.221820  0.103884 -0.219372  2.179068  0.578645  \n",
              "1    0.505041  0.922128  0.405464  1.886947  0.407544  1.431193  0.159015  \n",
              "2   -0.647099 -0.565453 -0.137190 -0.232586 -1.420808 -0.843064  0.274254  \n",
              "3    0.137507  1.186905  0.955207  0.589803  1.509390  0.992935  1.875483  \n",
              "4   -1.551728  0.239188 -0.882897  0.129474  0.019597 -0.322608  0.302670  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "495  0.388253  1.314865  0.244731 -0.051043  0.768067 -1.622517 -0.276086  \n",
              "496 -0.066838  1.210734  1.491540  1.586784 -0.445346  1.701997 -0.326600  \n",
              "497 -1.523764  0.714171  0.222749 -0.126531 -0.074166 -0.752975 -1.750938  \n",
              "498  0.697122  2.236943 -0.629723  0.969926 -1.121823 -0.413634  0.321612  \n",
              "499 -0.357252  0.055396  0.894034  0.415548  0.908002 -0.172811 -0.364571  \n",
              "\n",
              "[500 rows x 200 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f904830-5274-4dfb-8db3-09b55181a1c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v000</th>\n",
              "      <th>v001</th>\n",
              "      <th>v002</th>\n",
              "      <th>v003</th>\n",
              "      <th>v004</th>\n",
              "      <th>v005</th>\n",
              "      <th>v006</th>\n",
              "      <th>v007</th>\n",
              "      <th>v008</th>\n",
              "      <th>v009</th>\n",
              "      <th>...</th>\n",
              "      <th>v190</th>\n",
              "      <th>v191</th>\n",
              "      <th>v192</th>\n",
              "      <th>v193</th>\n",
              "      <th>v194</th>\n",
              "      <th>v195</th>\n",
              "      <th>v196</th>\n",
              "      <th>v197</th>\n",
              "      <th>v198</th>\n",
              "      <th>v199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.203777</td>\n",
              "      <td>-7.278026</td>\n",
              "      <td>2.756077</td>\n",
              "      <td>0.412740</td>\n",
              "      <td>-0.116626</td>\n",
              "      <td>0.414236</td>\n",
              "      <td>6.218588</td>\n",
              "      <td>0.018764</td>\n",
              "      <td>0.209555</td>\n",
              "      <td>0.005660</td>\n",
              "      <td>...</td>\n",
              "      <td>-8.551783</td>\n",
              "      <td>-5.323863</td>\n",
              "      <td>2.004479</td>\n",
              "      <td>-0.065859</td>\n",
              "      <td>-0.877748</td>\n",
              "      <td>0.221820</td>\n",
              "      <td>0.103884</td>\n",
              "      <td>-0.219372</td>\n",
              "      <td>2.179068</td>\n",
              "      <td>0.578645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.084936</td>\n",
              "      <td>0.328886</td>\n",
              "      <td>4.545345</td>\n",
              "      <td>0.678987</td>\n",
              "      <td>0.003042</td>\n",
              "      <td>-0.807901</td>\n",
              "      <td>-13.653907</td>\n",
              "      <td>-0.654958</td>\n",
              "      <td>-0.860854</td>\n",
              "      <td>-1.017529</td>\n",
              "      <td>...</td>\n",
              "      <td>1.195129</td>\n",
              "      <td>-20.574463</td>\n",
              "      <td>0.119288</td>\n",
              "      <td>0.505041</td>\n",
              "      <td>0.922128</td>\n",
              "      <td>0.405464</td>\n",
              "      <td>1.886947</td>\n",
              "      <td>0.407544</td>\n",
              "      <td>1.431193</td>\n",
              "      <td>0.159015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.769527</td>\n",
              "      <td>-1.213339</td>\n",
              "      <td>-1.821305</td>\n",
              "      <td>-0.816333</td>\n",
              "      <td>3.059691</td>\n",
              "      <td>-0.583517</td>\n",
              "      <td>22.961234</td>\n",
              "      <td>-1.034725</td>\n",
              "      <td>-0.039125</td>\n",
              "      <td>0.983415</td>\n",
              "      <td>...</td>\n",
              "      <td>2.926464</td>\n",
              "      <td>14.608653</td>\n",
              "      <td>-0.456923</td>\n",
              "      <td>-0.647099</td>\n",
              "      <td>-0.565453</td>\n",
              "      <td>-0.137190</td>\n",
              "      <td>-0.232586</td>\n",
              "      <td>-1.420808</td>\n",
              "      <td>-0.843064</td>\n",
              "      <td>0.274254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.094123</td>\n",
              "      <td>-0.567694</td>\n",
              "      <td>1.747513</td>\n",
              "      <td>0.033398</td>\n",
              "      <td>7.415277</td>\n",
              "      <td>-0.756049</td>\n",
              "      <td>-1.021780</td>\n",
              "      <td>-0.662921</td>\n",
              "      <td>-0.671345</td>\n",
              "      <td>-0.159661</td>\n",
              "      <td>...</td>\n",
              "      <td>4.750111</td>\n",
              "      <td>21.559404</td>\n",
              "      <td>0.188952</td>\n",
              "      <td>0.137507</td>\n",
              "      <td>1.186905</td>\n",
              "      <td>0.955207</td>\n",
              "      <td>0.589803</td>\n",
              "      <td>1.509390</td>\n",
              "      <td>0.992935</td>\n",
              "      <td>1.875483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.116567</td>\n",
              "      <td>-1.551208</td>\n",
              "      <td>9.343513</td>\n",
              "      <td>-1.785618</td>\n",
              "      <td>-2.651805</td>\n",
              "      <td>0.955870</td>\n",
              "      <td>-0.952141</td>\n",
              "      <td>-0.854849</td>\n",
              "      <td>-0.679621</td>\n",
              "      <td>0.682699</td>\n",
              "      <td>...</td>\n",
              "      <td>0.364826</td>\n",
              "      <td>24.729498</td>\n",
              "      <td>-0.585663</td>\n",
              "      <td>-1.551728</td>\n",
              "      <td>0.239188</td>\n",
              "      <td>-0.882897</td>\n",
              "      <td>0.129474</td>\n",
              "      <td>0.019597</td>\n",
              "      <td>-0.322608</td>\n",
              "      <td>0.302670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>-0.288139</td>\n",
              "      <td>-1.396761</td>\n",
              "      <td>-4.263799</td>\n",
              "      <td>0.749690</td>\n",
              "      <td>1.721721</td>\n",
              "      <td>-0.344043</td>\n",
              "      <td>19.469950</td>\n",
              "      <td>0.662457</td>\n",
              "      <td>0.557387</td>\n",
              "      <td>-0.190842</td>\n",
              "      <td>...</td>\n",
              "      <td>1.589264</td>\n",
              "      <td>17.684302</td>\n",
              "      <td>-1.333075</td>\n",
              "      <td>0.388253</td>\n",
              "      <td>1.314865</td>\n",
              "      <td>0.244731</td>\n",
              "      <td>-0.051043</td>\n",
              "      <td>0.768067</td>\n",
              "      <td>-1.622517</td>\n",
              "      <td>-0.276086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>0.153794</td>\n",
              "      <td>-1.877765</td>\n",
              "      <td>0.514750</td>\n",
              "      <td>3.191452</td>\n",
              "      <td>2.515170</td>\n",
              "      <td>0.214678</td>\n",
              "      <td>1.100869</td>\n",
              "      <td>-0.641812</td>\n",
              "      <td>-0.192485</td>\n",
              "      <td>2.340703</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.849789</td>\n",
              "      <td>-12.417970</td>\n",
              "      <td>0.906713</td>\n",
              "      <td>-0.066838</td>\n",
              "      <td>1.210734</td>\n",
              "      <td>1.491540</td>\n",
              "      <td>1.586784</td>\n",
              "      <td>-0.445346</td>\n",
              "      <td>1.701997</td>\n",
              "      <td>-0.326600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>0.128327</td>\n",
              "      <td>-2.151517</td>\n",
              "      <td>-6.010139</td>\n",
              "      <td>-5.710254</td>\n",
              "      <td>-2.606002</td>\n",
              "      <td>-0.326701</td>\n",
              "      <td>-3.537265</td>\n",
              "      <td>-0.786013</td>\n",
              "      <td>-0.985565</td>\n",
              "      <td>0.120138</td>\n",
              "      <td>...</td>\n",
              "      <td>-10.669278</td>\n",
              "      <td>-7.494708</td>\n",
              "      <td>0.520567</td>\n",
              "      <td>-1.523764</td>\n",
              "      <td>0.714171</td>\n",
              "      <td>0.222749</td>\n",
              "      <td>-0.126531</td>\n",
              "      <td>-0.074166</td>\n",
              "      <td>-0.752975</td>\n",
              "      <td>-1.750938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0.907801</td>\n",
              "      <td>2.899501</td>\n",
              "      <td>-2.170869</td>\n",
              "      <td>1.386165</td>\n",
              "      <td>4.658550</td>\n",
              "      <td>0.172423</td>\n",
              "      <td>2.034290</td>\n",
              "      <td>0.563519</td>\n",
              "      <td>-1.294684</td>\n",
              "      <td>0.853006</td>\n",
              "      <td>...</td>\n",
              "      <td>0.691517</td>\n",
              "      <td>-18.558853</td>\n",
              "      <td>1.667956</td>\n",
              "      <td>0.697122</td>\n",
              "      <td>2.236943</td>\n",
              "      <td>-0.629723</td>\n",
              "      <td>0.969926</td>\n",
              "      <td>-1.121823</td>\n",
              "      <td>-0.413634</td>\n",
              "      <td>0.321612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>0.173000</td>\n",
              "      <td>1.544216</td>\n",
              "      <td>7.862991</td>\n",
              "      <td>2.611334</td>\n",
              "      <td>-3.852684</td>\n",
              "      <td>-0.453429</td>\n",
              "      <td>30.162525</td>\n",
              "      <td>-0.319517</td>\n",
              "      <td>-0.718359</td>\n",
              "      <td>1.447191</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.883870</td>\n",
              "      <td>28.225737</td>\n",
              "      <td>0.104841</td>\n",
              "      <td>-0.357252</td>\n",
              "      <td>0.055396</td>\n",
              "      <td>0.894034</td>\n",
              "      <td>0.415548</td>\n",
              "      <td>0.908002</td>\n",
              "      <td>-0.172811</td>\n",
              "      <td>-0.364571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 200 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f904830-5274-4dfb-8db3-09b55181a1c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f904830-5274-4dfb-8db3-09b55181a1c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f904830-5274-4dfb-8db3-09b55181a1c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "url = 'https://raw.githubusercontent.com/aprendizaje-automatico-dc-uba-ar/material/main/tp/01_aprendizaje_supervisado/datos/minions_publicos.csv'\n",
        "minions_dataset = pd.read_csv(url)\n",
        "\n",
        "y = minions_dataset.iloc[:,-1:]\n",
        "print(y[y[\"target\"] == 1])\n",
        "\n",
        "del minions_dataset[minions_dataset.columns[-1]]\n",
        "print(\"\\n Features\")\n",
        "minions_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto nos indica que hay 154 de clase positiva y el resto de clase negativa. Es decir, está desbalanceado en aproximadamente 30/70. Tenemos que tener en cuenta entonces esto a la hora de splitear los datos."
      ],
      "metadata": {
        "id": "5eX-IzBzwcaX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8pr9QvXViqQ"
      },
      "source": [
        "## Ejercicio 1\n",
        "\n",
        "### Separación de datos\n",
        "\n",
        "Contarán con una cantidad limitada de datos, por lo cual es importante tomar una buena decisión en el momento de empezar a utilizarlos. \n",
        "\n",
        "Evaluar y justificar cómo separarán sus datos para desarrollo y para evaluación. Los datos seleccionados para la competencia fueron extraidos al azar. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Separación de datos\n",
        "\n",
        "Para la separación de datos de evaluación, lo primero que tuvimos en cuenta fue evaluar la distribucion de etiquetas de los minions entrevistados. Al revisar esto notamos que hay un desbalance entre minions que fueron aceptados vs aquellos que no (aproximadamente fueron aceptados el 30% de los postulantes). Por lo tanto es primordial que mantengamos la proporción entre estas dos clases cuando hagamos los _k-folds_, ya que de no realizarlo nuestro predictor no se entrenaría con las proporciones correctas de los datos. \n",
        "\n",
        "En segundo lugar tenemos que tener en cuenta la cantidad de candidatos que tenemos. Solamente 500 postulados resulta una base de datos más bien reducida, por lo que no tenemos margen a la hora de decidir nuestra estrategia a la hora de separación de datos. Lo que nuestro grupo propone es realizar una separación del 10% para utilizar en la etapa de evaluación final, manteniendo el 90% restante para el desarrollo de nuestros modelos (todo esto haciendo _stratified split_ para que el desbalance de datos no nos perjudique a futuro).\n",
        "\n",
        "#########################\n",
        "Revisar juntos, cuando hacemos el train_test_split se elije al azar, se mantiene las proporciones de las clases pero se hace al azar, no estamos considerando el desbalanceo. mas datos para eval??"
      ],
      "metadata": {
        "id": "mxZBE44sBV78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_dev, X_eval, y_dev, y_eval = train_test_split(minions_dataset.values, y.values, shuffle=True, random_state=4, test_size=0.1) # quedan 15 positivos para eval :_ _(\n",
        "\n",
        "print(f\"X_train dimensión: {X_dev.shape}\")\n",
        "print(f\"y_train dimensión: {y_dev.shape}\")\n",
        "\n",
        "print(f\"X_test dimensión: {X_eval.shape}\")\n",
        "print(f\"y_test dimensión: {y_eval.shape}\")\n"
      ],
      "metadata": {
        "id": "nd48vRPt3KU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "877691e4-74bc-4c61-b550-fc9cd74e7c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train dimensión: (450, 200)\n",
            "y_train dimensión: (450, 1)\n",
            "X_test dimensión: (50, 200)\n",
            "y_test dimensión: (50, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8AztvHdVYdX"
      },
      "source": [
        "## Ejercicio 2\n",
        "\n",
        "\n",
        "### Construcción de modelos\n",
        "\n",
        "Para este punto, la tarea consiste en construir y evaluar modelos de tipo árbol de decisión, de manera de obtener una **estimación realista de la performance** de los mismos. \n",
        "\n",
        "1. Entrenar un árbol de decisión con altura máxima 3 y el resto de los hiperparámetros en default.\n",
        "\n",
        "1. Estimar la performance del modelo utilizando _K-fold cross validation_ con `K=5`, con las métricas _Accuracy_ y _ROC AUC_. \n",
        "\n",
        "   En esta oportunidad se va a pedir, además de calcular el score global (como vimos en clase), que calculen las métricas para cada fold por separado.\n",
        "   Reportar el resultado en una tabla similar a:\n",
        "\n",
        "      <table>\n",
        "      <thead>\n",
        "      <tr>\n",
        "      <th align=\"center\">Permutación</th>\n",
        "      <th>Accuracy (training)</th>\n",
        "      <th>Accuracy (validación)</th>\n",
        "      <th>AUC ROC (training)</th>\n",
        "      <th>AUC ROC (validación)</th>\n",
        "      </tr>\n",
        "      </thead>\n",
        "      <tbody>\n",
        "      <tr>\n",
        "      <td align=\"center\">1</td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">2</td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">3</td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">4</td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">5</td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">Global</td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      <td></td>\n",
        "      </tr>\n",
        "      </tbody>\n",
        "      </table>\n",
        "\n",
        "      **Importante**: de acá en más sólamente utilizaremos el score global cuando hagamos _K-fold cross-validation_.\n",
        " \n",
        "1. Explorar las siguientes combinaciones de parámetros para  árboles de decisión (siguiendo con $k-fold$ con $k=5$) utilizando [ParameterGrid](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html) de _scikit learn_. No está permitido utilizar `GridSearchCV` en este ejercicio.\n",
        "\n",
        "   <table>\n",
        "   <thead>\n",
        "   <tr>\n",
        "   <th align=\"center\">Altura máxima</th>\n",
        "   <th align=\"center\">Criterio de corte</th>\n",
        "   <th>Accuracy (training)</th>\n",
        "   <th>Accuracy (validación)</th>\n",
        "   </tr>\n",
        "   </thead>\n",
        "   <tbody><tr>\n",
        "   <td align=\"center\">3</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td></td>\n",
        "   <td></td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">5</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td></td>\n",
        "   <td></td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">Infinito</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td></td>\n",
        "   <td></td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">3</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td></td>\n",
        "   <td></td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">5</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td></td>\n",
        "   <td></td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">Infinito</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td></td>\n",
        "   <td></td>\n",
        "   </tr>\n",
        "   </tbody></table>\n",
        "\n",
        "\n",
        "   ¿Qué conclusiones se pueden sacar de esta tabla?   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Construcción de modelos"
      ],
      "metadata": {
        "id": "6G3jEonGDxuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1) Árbol default con max_height 3"
      ],
      "metadata": {
        "id": "PGUSW2t3UCF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "arbol_gini_3 = DecisionTreeClassifier(max_depth=3)"
      ],
      "metadata": {
        "id": "qPq5DoemUCbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2) Iteradores de cross validation"
      ],
      "metadata": {
        "id": "4aIzNpJyNPZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
        "\n",
        "# consultamos y podemos usar stratifieldk fold, sacaria el otro creo para no complejizar pero eventualmente podriamos comparar los.\n",
        "# evaluar que tanto conviene entrenar balanceado vs entrenar con las proporciones reales.\n",
        "balanced_k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Validar si podemos usar esto porque el enunciado dice k fold\n",
        "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=4)\n",
        "\n",
        "X_train_cv = []\n",
        "y_train_cv = []\n",
        "X_test_cv = []\n",
        "y_test_cv = []\n",
        "\n",
        "for train_index, test_index in sss.split(X_dev, y_dev):\n",
        "    X_train = X_dev[train_index]\n",
        "    X_test = X_dev[test_index]\n",
        "    y_train = y_dev[train_index]\n",
        "    y_test = y_dev[test_index]\n",
        "    \n",
        "    X_train_cv.append(X_train)\n",
        "    X_test_cv.append(X_test)\n",
        "    y_train_cv.append(y_train)\n",
        "    y_test_cv.append(y_test)\n"
      ],
      "metadata": {
        "id": "LVHBdOaASR73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2) Métricas"
      ],
      "metadata": {
        "id": "EnSjS6fiQi3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Scoring metrics\n",
        "\n",
        "def tn(y, y_pred): return metrics.confusion_matrix(y, y_pred)[0, 0];\n",
        "def fp(y, y_pred): return metrics.confusion_matrix(y, y_pred)[0, 1];\n",
        "def fn(y, y_pred): return metrics.confusion_matrix(y, y_pred)[1, 0];\n",
        "def tp(y, y_pred): return metrics.confusion_matrix(y, y_pred)[1, 1];\n",
        "def specificity(y, y_pred): return tn(y, y_pred)/(tn(y, y_pred) + fp(y,y_pred));\n",
        "def precision(y, y_pred): return tp(y, y_pred)/(tp(y, y_pred) + fp(y, y_pred));\n",
        "def recall(y, y_pred): return tp(y, y_pred)/(tp(y, y_pred) + fn(y, y_pred));\n",
        "def f1(y, y_pred): return 2 * precision(y, y_pred) * recall(y, y_pred) / (precision(y, y_pred) + recall(y_pred))\n",
        "def accuracy(y,y_pred): return metrics.accuracy_score(y, y_pred) # creo q se puede borrar, ver q no se use\n",
        "\n",
        "scoring = {#'precision': metrics.make_scorer(precision), \n",
        "           #'recall': metrics.make_scorer(recall),\n",
        "           #'specificity': metrics.make_scorer(specificity),\n",
        "           #'tp': metrics.make_scorer(tp),\n",
        "           #'tn': metrics.make_scorer(tn),\n",
        "           #'fp': metrics.make_scorer(fp),\n",
        "           #'fn': metrics.make_scorer(fn),\n",
        "           #'f1_score': metrics.make_scorer(f1),\n",
        "           'roc_auc': metrics.make_scorer(metrics.roc_auc_score, needs_proba=True),\n",
        "           'accuracy': metrics.make_scorer(metrics.accuracy_score)\n",
        "           }\n"
      ],
      "metadata": {
        "id": "SBOIPn3sQ97s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2) Árbol default (gini) altura 3 + Crossvalidation K=5 + Accuracy y AUC \n",
        "\n",
        "Integramos las 3 celdas anteriores para correr los folds y calcular las metricas para un classificador"
      ],
      "metadata": {
        "id": "Mkv4DgcVNa19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "# Crossvalidation with one fixed configuration of hyperparameters.\n",
        "# scoring is a dictionary with the metrics we want to calculate\n",
        "# cv is a cross validation iterator\n",
        "\n",
        "def cross_validate_uba(clf, X, y, scoring, cv, score_train=True):\n",
        "    n = len(y)\n",
        "    k = cv.n_splits\n",
        "\n",
        "    train_global_preds = np.empty(n, dtype=list) # train samples will be scored k-1 times\n",
        "    train_global_preds[:] = [ [] for i in range(n)]\n",
        "    train_global_probas = np.empty(n, dtype=list)  # we will save only the proba of POSITIVE class\n",
        "    train_global_probas[:] = [ [] for i in range(n)]\n",
        "    test_global_preds = np.zeros(n)\n",
        "    test_global_probas = np.zeros(n)\n",
        "    \n",
        "    cv_results = dict(train_global_preds=train_global_preds,\n",
        "                      train_global_probas=train_global_probas,\n",
        "                      train_folds_accuracy=[],\n",
        "                      train_folds_auc=[], \n",
        "                      test_global_preds=test_global_preds,\n",
        "                      test_global_probas=test_global_probas,\n",
        "                      test_folds_accuracy=[],\n",
        "                      test_folds_auc=[],\n",
        "                      ) \n",
        "\n",
        "    for fold_idx, (train_idxs, test_idxs) in enumerate(cv.split(X, y)):\n",
        "        X_train = X[train_idxs]\n",
        "        y_train = y[train_idxs]\n",
        "        X_test = X[test_idxs]\n",
        "        y_test = y[test_idxs]\n",
        "        \n",
        "        clf.fit(X_train, y_train)\n",
        "        if score_train:\n",
        "            # Scores sobre train\n",
        "            y_pred_train = clf.predict(X_train)\n",
        "            y_proba_train = clf.predict_proba(X_train)[:, 1]\n",
        "            # para cada instancia busco su lista de scores de cada fold y le agrego el score de este fold\n",
        "            for fold_scores_i, fold_score_i in zip(cv_results[\"train_global_preds\"][train_idxs], y_pred_train):\n",
        "              fold_scores_i.append(fold_score_i)\n",
        "            for fold_scores_i, fold_score_i in zip(cv_results[\"train_global_probas\"][train_idxs], y_proba_train):\n",
        "              fold_scores_i.append(fold_score_i)\n",
        "            \n",
        "            cv_results[\"train_folds_accuracy\"].append( scoring[\"accuracy\"]._score_func(y_train, y_pred_train, **scoring[\"accuracy\"]._kwargs) )\n",
        "            cv_results[\"train_folds_auc\"].append( scoring[\"roc_auc\"]._score_func(y_train, y_proba_train, **scoring[\"roc_auc\"]._kwargs) )\n",
        "\n",
        "        # Scores sobre test\n",
        "        y_pred_test = clf.predict(X_test)\n",
        "        y_proba_test = clf.predict_proba(X_test)[:, 1]\n",
        "        cv_results[\"test_global_preds\"][test_idxs] = y_pred_test\n",
        "        cv_results[\"test_global_probas\"][test_idxs] = y_proba_test\n",
        "        cv_results[\"test_folds_accuracy\"].append( scoring[\"accuracy\"]._score_func(y_test, y_pred_test, **scoring[\"accuracy\"]._kwargs))\n",
        "        cv_results[\"test_folds_auc\"].append( scoring[\"roc_auc\"]._score_func(y_test, y_proba_test, **scoring[\"roc_auc\"]._kwargs))\n",
        "    \n",
        "\n",
        "    return cv_results\n",
        "\n",
        "def cv_with_metrics(classifier_to_train, X, y, scoring, cv, score_train=False):\n",
        "\n",
        "    if isinstance(classifier_to_train, DecisionTreeClassifier):\n",
        "        clf = classifier_to_train\n",
        "    else: \n",
        "        clf = make_pipeline(preprocessing.StandardScaler(), clf)\n",
        "\n",
        "    cv_results = cross_validate_uba(clf, X, y=y, scoring=scoring, cv=cv, score_train=score_train)\n",
        "\n",
        "    print(f'Crossvalidation metrics for {clf}...\\n')\n",
        "    \n",
        "    # Ver si tiene sentido usar repeated k fold para calcular intervalos de confianza de las metricas, \n",
        "    # para los globales podriamos tomar la mediana de scores globales, y para cada instancia \n",
        "    # solo guardar la suma del score en cada fold de train\n",
        "    \n",
        "    if score_train:\n",
        "        # for each train instance we calculate the most common label that was predicted so we can then calculate a global accuracy\n",
        "        most_common_preds = [Counter(instance_preds).most_common(1)[0][0] for instance_preds in cv_results['train_global_preds']]\n",
        "        cv_results['train_global_accuracy'] = scoring[\"accuracy\"]._score_func(y, most_common_preds, **scoring[\"accuracy\"]._kwargs)\n",
        "\n",
        "        # for each train instance we calculate the mean or median of probas across the different folds so we can then calculate a global AUC\n",
        "        global_probas = [np.median(instance_probas) for instance_probas in cv_results['train_global_probas']]\n",
        "        cv_results['train_global_auc'] = scoring[\"roc_auc\"]._score_func(y, global_probas, **scoring[\"roc_auc\"]._kwargs)\n",
        "\n",
        "    cv_results['test_global_accuracy'] = scoring[\"accuracy\"]._score_func(y, cv_results['test_global_preds'], **scoring[\"accuracy\"]._kwargs)\n",
        "    cv_results['test_global_auc'] = scoring[\"roc_auc\"]._score_func(y, cv_results['test_global_probas'], **scoring[\"roc_auc\"]._kwargs)\n",
        "\n",
        "    if score_train:\n",
        "        print(f\"\"\"Accuracy [TRAIN]:\n",
        "    Global --> {cv_results['train_global_accuracy']:.3f}\n",
        "    Folds: \n",
        "    \\tRaw --> {list(map(lambda x: round(x, 3), cv_results['train_folds_accuracy']))}\n",
        "    \\tMean --> {np.mean(cv_results['train_folds_accuracy']):.3f}\n",
        "    \\tSTD --> {np.std(cv_results['train_folds_accuracy']):.3f}\n",
        "    \\tMedian --> {np.median(cv_results['train_folds_accuracy']):.3f}\"\"\")\n",
        "\n",
        "    print(f\"\"\"Accuracy [TEST]:\n",
        "    Global --> {cv_results['test_global_accuracy']:.3f}\n",
        "    Folds: \n",
        "    \\tRaw --> {list(map(lambda x: round(x, 3), cv_results['test_folds_accuracy']))}\n",
        "    \\tMean --> {np.mean(cv_results['test_folds_accuracy']):.3f}\n",
        "    \\tSTD --> {np.std(cv_results['test_folds_accuracy']):.3f}\n",
        "    \\tMedian --> {np.median(cv_results['test_folds_accuracy']):.3f}\"\"\")\n",
        "\n",
        "    if score_train:\n",
        "        print(f\"\"\"AUC [TRAIN]:\n",
        "    Global --> {cv_results['train_global_auc']:.3f}\n",
        "    Folds: \n",
        "    \\tRaw --> {list(map(lambda x: round(x, 3), cv_results['train_folds_auc']))}\n",
        "    \\tMean --> {np.mean(cv_results['train_folds_auc']):.3f}\n",
        "    \\tSTD --> {np.std(cv_results['train_folds_auc']):.3f} \n",
        "    \\tMedian --> {np.median(cv_results['train_folds_auc']):.3f}\"\"\")\n",
        "        \n",
        "    print(f\"\"\"AUC [TEST]:\n",
        "    Global --> {cv_results['test_global_auc']:.3f}\n",
        "    Folds: \n",
        "    \\tRaw --> {list(map(lambda x: round(x, 3), cv_results['test_folds_auc']))}\n",
        "    \\tMean --> {np.mean(cv_results['test_folds_auc']):.3f}\n",
        "    \\tSTD --> {np.std(cv_results['test_folds_auc']):.3f} \n",
        "    \\tMedian --> {np.median(cv_results['test_folds_auc']):.3f}\"\"\")\n"
      ],
      "metadata": {
        "id": "2DNwIAfmZ-Oz"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corremos el K fold cross validation para una configuracion fija\n",
        "cv_with_metrics(arbol_gini_3, X_dev, y_dev, scoring, cv=balanced_k_fold, score_train=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayhgyzQjQUNk",
        "outputId": "ff037efa-0ad8-4d1d-cd37-2c39dd838ff1"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crossvalidation metrics for DecisionTreeClassifier(max_depth=3)...\n",
            "\n",
            "Accuracy [TRAIN]:\n",
            "    Global --> 0.858\n",
            "    Folds: \n",
            "    \tRaw --> [0.822, 0.775, 0.808, 0.828, 0.822]\n",
            "    \tMean --> 0.811\n",
            "    \tSTD --> 0.019\n",
            "    \tMedian --> 0.822\n",
            "Accuracy [TEST]:\n",
            "    Global --> 0.658\n",
            "    Folds: \n",
            "    \tRaw --> [0.611, 0.667, 0.689, 0.622, 0.7]\n",
            "    \tMean --> 0.658\n",
            "    \tSTD --> 0.035\n",
            "    \tMedian --> 0.667\n",
            "AUC [TRAIN]:\n",
            "    Global --> 0.896\n",
            "    Folds: \n",
            "    \tRaw --> [0.794, 0.771, 0.763, 0.853, 0.797]\n",
            "    \tMean --> 0.796\n",
            "    \tSTD --> 0.032 \n",
            "    \tMedian --> 0.794\n",
            "AUC [TEST]:\n",
            "    Global --> 0.600\n",
            "    Folds: \n",
            "    \tRaw --> [0.547, 0.609, 0.574, 0.501, 0.736]\n",
            "    \tMean --> 0.593\n",
            "    \tSTD --> 0.080 \n",
            "    \tMedian --> 0.574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados\n",
        "<table>\n",
        "      <thead>\n",
        "      <tr>\n",
        "      <th align=\"center\">Permutación</th>\n",
        "      <th>Accuracy (training)</th>\n",
        "      <th>Accuracy (validación)</th>\n",
        "      <th>AUC ROC (training)</th>\n",
        "      <th>AUC ROC (validación)</th>\n",
        "      </tr>\n",
        "      </thead>\n",
        "      <tbody>\n",
        "      <tr> \n",
        "      <td align=\"center\">1</td>\n",
        "      <td>0.822</td>\n",
        "      <td>0.611</td>\n",
        "      <td>0.794</td>\n",
        "      <td>0.547</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">2</td>\n",
        "      <td>0.775</td>\n",
        "      <td>0.667</td>\n",
        "      <td>0.771</td>\n",
        "      <td>0.609</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">3</td>\n",
        "      <td>0.808</td>\n",
        "      <td>0.689</td>\n",
        "      <td>0.763</td>\n",
        "      <td>0.574</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">4</td>\n",
        "      <td>0.828</td>\n",
        "      <td>0.622</td>\n",
        "      <td>0.853</td>\n",
        "      <td>0.501</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">5</td>\n",
        "      <td>0.822</td>\n",
        "      <td>0.7</td>\n",
        "      <td>0.797</td>\n",
        "      <td>0.736</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">Global</td>\n",
        "      <td>0.858</td>\n",
        "      <td>0.658</td>\n",
        "      <td>0.896</td>\n",
        "      <td>0.6</td>\n",
        "      </tr>\n",
        "      </tbody>\n",
        "      </table>"
      ],
      "metadata": {
        "id": "CurMQznvQmTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.3) Parameter grid sobre el arbol"
      ],
      "metadata": {
        "id": "tTETHVB8NoEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "def parameter_grid_search(classifier, grid):\n",
        "    param_grid = ParameterGrid(grid)\n",
        "    for config in param_grid:\n",
        "        print('---------------------------------------------------------------')\n",
        "        classifier.set_params(**config)\n",
        "        cv_with_metrics(classifier, X_dev, y_dev, scoring, cv=balanced_k_fold, score_train=True)\n"
      ],
      "metadata": {
        "id": "lIGbkdVsVkLx"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_arbol = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 3, 5]\n",
        "}\n",
        "parameter_grid_search(classifier=arbol_gini_3, grid=grid_arbol)"
      ],
      "metadata": {
        "id": "_imcGczrQLZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afca4b9e-bbd1-4044-d919-b5ef52d8f06c"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------\n",
            "Crossvalidation metrics for DecisionTreeClassifier()...\n",
            "\n",
            "Accuracy [TRAIN]:\n",
            "    Global --> 1.000\n",
            "    Folds: \n",
            "    \tRaw --> [1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "    \tMean --> 1.000\n",
            "    \tSTD --> 0.000\n",
            "    \tMedian --> 1.000\n",
            "Accuracy [TEST]:\n",
            "    Global --> 0.631\n",
            "    Folds: \n",
            "    \tRaw --> [0.556, 0.656, 0.689, 0.522, 0.733]\n",
            "    \tMean --> 0.631\n",
            "    \tSTD --> 0.080\n",
            "    \tMedian --> 0.656\n",
            "AUC [TRAIN]:\n",
            "    Global --> 1.000\n",
            "    Folds: \n",
            "    \tRaw --> [1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "    \tMean --> 1.000\n",
            "    \tSTD --> 0.000 \n",
            "    \tMedian --> 1.000\n",
            "AUC [TEST]:\n",
            "    Global --> 0.566\n",
            "    Folds: \n",
            "    \tRaw --> [0.46, 0.613, 0.608, 0.467, 0.679]\n",
            "    \tMean --> 0.565\n",
            "    \tSTD --> 0.087 \n",
            "    \tMedian --> 0.608\n",
            "---------------------------------------------------------------\n",
            "Crossvalidation metrics for DecisionTreeClassifier(max_depth=3)...\n",
            "\n",
            "Accuracy [TRAIN]:\n",
            "    Global --> 0.858\n",
            "    Folds: \n",
            "    \tRaw --> [0.822, 0.775, 0.808, 0.828, 0.822]\n",
            "    \tMean --> 0.811\n",
            "    \tSTD --> 0.019\n",
            "    \tMedian --> 0.822\n",
            "Accuracy [TEST]:\n",
            "    Global --> 0.656\n",
            "    Folds: \n",
            "    \tRaw --> [0.611, 0.656, 0.689, 0.622, 0.7]\n",
            "    \tMean --> 0.656\n",
            "    \tSTD --> 0.035\n",
            "    \tMedian --> 0.656\n",
            "AUC [TRAIN]:\n",
            "    Global --> 0.896\n",
            "    Folds: \n",
            "    \tRaw --> [0.794, 0.771, 0.763, 0.853, 0.797]\n",
            "    \tMean --> 0.796\n",
            "    \tSTD --> 0.032 \n",
            "    \tMedian --> 0.794\n",
            "AUC [TEST]:\n",
            "    Global --> 0.597\n",
            "    Folds: \n",
            "    \tRaw --> [0.547, 0.594, 0.574, 0.501, 0.736]\n",
            "    \tMean --> 0.590\n",
            "    \tSTD --> 0.079 \n",
            "    \tMedian --> 0.574\n",
            "---------------------------------------------------------------\n",
            "Crossvalidation metrics for DecisionTreeClassifier(max_depth=5)...\n",
            "\n",
            "Accuracy [TRAIN]:\n",
            "    Global --> 0.956\n",
            "    Folds: \n",
            "    \tRaw --> [0.908, 0.878, 0.903, 0.956, 0.925]\n",
            "    \tMean --> 0.914\n",
            "    \tSTD --> 0.026\n",
            "    \tMedian --> 0.908\n",
            "Accuracy [TEST]:\n",
            "    Global --> 0.640\n",
            "    Folds: \n",
            "    \tRaw --> [0.611, 0.644, 0.7, 0.522, 0.722]\n",
            "    \tMean --> 0.640\n",
            "    \tSTD --> 0.071\n",
            "    \tMedian --> 0.644\n",
            "AUC [TRAIN]:\n",
            "    Global --> 0.988\n",
            "    Folds: \n",
            "    \tRaw --> [0.931, 0.878, 0.887, 0.98, 0.928]\n",
            "    \tMean --> 0.921\n",
            "    \tSTD --> 0.036 \n",
            "    \tMedian --> 0.928\n",
            "AUC [TEST]:\n",
            "    Global --> 0.535\n",
            "    Folds: \n",
            "    \tRaw --> [0.476, 0.599, 0.566, 0.52, 0.582]\n",
            "    \tMean --> 0.549\n",
            "    \tSTD --> 0.045 \n",
            "    \tMedian --> 0.566\n",
            "---------------------------------------------------------------\n",
            "Crossvalidation metrics for DecisionTreeClassifier(criterion='entropy')...\n",
            "\n",
            "Accuracy [TRAIN]:\n",
            "    Global --> 1.000\n",
            "    Folds: \n",
            "    \tRaw --> [1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "    \tMean --> 1.000\n",
            "    \tSTD --> 0.000\n",
            "    \tMedian --> 1.000\n",
            "Accuracy [TEST]:\n",
            "    Global --> 0.647\n",
            "    Folds: \n",
            "    \tRaw --> [0.644, 0.644, 0.611, 0.633, 0.7]\n",
            "    \tMean --> 0.647\n",
            "    \tSTD --> 0.029\n",
            "    \tMedian --> 0.644\n",
            "AUC [TRAIN]:\n",
            "    Global --> 1.000\n",
            "    Folds: \n",
            "    \tRaw --> [1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "    \tMean --> 1.000\n",
            "    \tSTD --> 0.000 \n",
            "    \tMedian --> 1.000\n",
            "AUC [TEST]:\n",
            "    Global --> 0.581\n",
            "    Folds: \n",
            "    \tRaw --> [0.587, 0.595, 0.532, 0.577, 0.616]\n",
            "    \tMean --> 0.581\n",
            "    \tSTD --> 0.028 \n",
            "    \tMedian --> 0.587\n",
            "---------------------------------------------------------------\n",
            "Crossvalidation metrics for DecisionTreeClassifier(criterion='entropy', max_depth=3)...\n",
            "\n",
            "Accuracy [TRAIN]:\n",
            "    Global --> 0.782\n",
            "    Folds: \n",
            "    \tRaw --> [0.744, 0.753, 0.794, 0.806, 0.761]\n",
            "    \tMean --> 0.772\n",
            "    \tSTD --> 0.024\n",
            "    \tMedian --> 0.761\n",
            "Accuracy [TEST]:\n",
            "    Global --> 0.691\n",
            "    Folds: \n",
            "    \tRaw --> [0.711, 0.689, 0.689, 0.656, 0.711]\n",
            "    \tMean --> 0.691\n",
            "    \tSTD --> 0.020\n",
            "    \tMedian --> 0.689\n",
            "AUC [TRAIN]:\n",
            "    Global --> 0.896\n",
            "    Folds: \n",
            "    \tRaw --> [0.787, 0.783, 0.776, 0.821, 0.764]\n",
            "    \tMean --> 0.786\n",
            "    \tSTD --> 0.019 \n",
            "    \tMedian --> 0.783\n",
            "AUC [TEST]:\n",
            "    Global --> 0.626\n",
            "    Folds: \n",
            "    \tRaw --> [0.645, 0.611, 0.58, 0.543, 0.727]\n",
            "    \tMean --> 0.621\n",
            "    \tSTD --> 0.063 \n",
            "    \tMedian --> 0.611\n",
            "---------------------------------------------------------------\n",
            "Crossvalidation metrics for DecisionTreeClassifier(criterion='entropy', max_depth=5)...\n",
            "\n",
            "Accuracy [TRAIN]:\n",
            "    Global --> 0.909\n",
            "    Folds: \n",
            "    \tRaw --> [0.847, 0.847, 0.85, 0.892, 0.842]\n",
            "    \tMean --> 0.856\n",
            "    \tSTD --> 0.018\n",
            "    \tMedian --> 0.847\n",
            "Accuracy [TEST]:\n",
            "    Global --> 0.651\n",
            "    Folds: \n",
            "    \tRaw --> [0.633, 0.633, 0.622, 0.678, 0.689]\n",
            "    \tMean --> 0.651\n",
            "    \tSTD --> 0.027\n",
            "    \tMedian --> 0.633\n",
            "AUC [TRAIN]:\n",
            "    Global --> 0.986\n",
            "    Folds: \n",
            "    \tRaw --> [0.932, 0.917, 0.901, 0.913, 0.907]\n",
            "    \tMean --> 0.914\n",
            "    \tSTD --> 0.011 \n",
            "    \tMedian --> 0.913\n",
            "AUC [TEST]:\n",
            "    Global --> 0.563\n",
            "    Folds: \n",
            "    \tRaw --> [0.541, 0.537, 0.503, 0.572, 0.632]\n",
            "    \tMean --> 0.557\n",
            "    \tSTD --> 0.043 \n",
            "    \tMedian --> 0.541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados\n",
        "\n",
        "<table>\n",
        "   <thead>\n",
        "   <tr>\n",
        "   <th align=\"center\">Altura máxima</th>\n",
        "   <th align=\"center\">Criterio de corte</th>\n",
        "   <th>Accuracy (training)</th>\n",
        "   <th>Accuracy (validación)</th>\n",
        "   </tr>\n",
        "   </thead>\n",
        "   <tbody><tr>\n",
        "   <td align=\"center\">3</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td>0.8</td>\n",
        "   <td>0.67</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">5</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td>0.91</td>\n",
        "   <td>0.67</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">Infinito</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td>1.0</td>\n",
        "   <td>0.67</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">3</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td>0.78</td>\n",
        "   <td>0.64</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">5</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td>0.89</td>\n",
        "   <td>0.64</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">Infinito</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td>1.0</td>\n",
        "   <td>0.63</td>\n",
        "   </tr>\n",
        "   </tbody></table>"
      ],
      "metadata": {
        "id": "ssG-8zVoWeom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2 y 2.3) v0"
      ],
      "metadata": {
        "id": "GCCIb5S2OQ4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "BBB = 0\n",
        "CCC = 0\n",
        "DDD = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier(max_depth=3)\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  y_pred_test = arbol.predict(X_train_cv[i])\n",
        "  y_pred_cv.append(y_pred_test)\n",
        "\n",
        "  # print(y_pred)\n",
        "\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el train set: {arbol.score(X_train_cv[i], y_train_cv[i])}\")\n",
        "\n",
        "\n",
        "  # REVISAR, creo que estan al reves los parametros https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score\n",
        "  # y que hay que usarla con predict_proba \n",
        "  auc_train = roc_auc_score(y_pred_test, y_train_cv[i])\n",
        "  print(\"AUC de la curva ROC sobre el train set:\", auc_train)\n",
        "\n",
        "\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  auc_test = roc_auc_score(y_pred, y_test_cv[i])\n",
        "  print(\"AUC de la curva ROC sobre el test set:\", auc_test)\n",
        "\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  BBB += auc_test\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "  DDD += auc_train\n",
        "\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"AUC promedio de test:\", BBB/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)\n",
        "print(\"AUC promedio de train:\", DDD/5)\n",
        "\n"
      ],
      "metadata": {
        "id": "zrk7My-dVtKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resultados**<table>\n",
        "      <thead>\n",
        "      <tr>\n",
        "      <th align=\"center\">Permutación</th>\n",
        "      <th>Accuracy (training)</th>\n",
        "      <th>Accuracy (validación)</th>\n",
        "      <th>AUC ROC (training)</th>\n",
        "      <th>AUC ROC (validación)</th>\n",
        "      </tr>\n",
        "      </thead>\n",
        "      <tbody>\n",
        "      <tr>\n",
        "      <td align=\"center\">1</td>\n",
        "      <td>0,769</td>\n",
        "      <td>0.722</td>\n",
        "      <td>0.815</td>\n",
        "      <td>0.759</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">2</td>\n",
        "      <td>0.806</td>\n",
        "      <td>0.667</td>\n",
        "      <td>0.774</td>\n",
        "      <td>0.622</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">3</td>\n",
        "      <td>0.841</td>\n",
        "      <td>0.689</td>\n",
        "      <td>0.837</td>\n",
        "      <td>0.614</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">4</td>\n",
        "      <td>0.786</td>\n",
        "      <td>0.6</td>\n",
        "      <td>0.757</td>\n",
        "      <td>0.493</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">5</td>\n",
        "      <td>0.839</td>\n",
        "      <td>0.711</td>\n",
        "      <td>0.841</td>\n",
        "      <td>0.655</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">Global</td>\n",
        "      <td>0.678</td>\n",
        "      <td>0.808</td>\n",
        "      <td>0.817</td>\n",
        "      <td>0.629</td>\n",
        "      </tr>\n",
        "      </tbody>\n",
        "      </table>"
      ],
      "metadata": {
        "id": "BBP2U-1wV0fC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "CCC = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier(max_depth=5)\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  # print(y_pred)\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)"
      ],
      "metadata": {
        "id": "4Dl6YZHaM0bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "CCC = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier()\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  # print(y_pred)\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)"
      ],
      "metadata": {
        "id": "aZZobgYrVVJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "CCC = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  # print(y_pred)\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)"
      ],
      "metadata": {
        "id": "zPswfptgWRj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "CCC = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  # print(y_pred)\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)"
      ],
      "metadata": {
        "id": "i7MCZrIuWRsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "CCC = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier(criterion='entropy')\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  # print(y_pred)\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)"
      ],
      "metadata": {
        "id": "Ju7mq4bFWRyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table>\n",
        "   <thead>\n",
        "   <tr>\n",
        "   <th align=\"center\">Altura máxima</th>\n",
        "   <th align=\"center\">Criterio de corte</th>\n",
        "   <th>Accuracy (training)</th>\n",
        "   <th>Accuracy (validación)</th>\n",
        "   </tr>\n",
        "   </thead>\n",
        "   <tbody><tr>\n",
        "   <td align=\"center\">3</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td>0.8</td>\n",
        "   <td>0.67</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">5</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td>0.91</td>\n",
        "   <td>0.67</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">Infinito</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td>1.0</td>\n",
        "   <td>0.67</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">3</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td>0.78</td>\n",
        "   <td>0.64</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">5</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td>0.89</td>\n",
        "   <td>0.64</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">Infinito</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td>1.0</td>\n",
        "   <td>0.63</td>\n",
        "   </tr>\n",
        "   </tbody></table>"
      ],
      "metadata": {
        "id": "XKxTFERbc3xQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "conclusiones: (a checkear si estan bien calculadas las métricas, siento que tendrian que dar otra cosa) Podemos observar que un aumento en la altura máxima de los arboles no se condice con una mejora en la performance en la etapa de validacion. Esto se debe a que si los arboles tienen altura infinita van a asegurarse de que podamos clasificar correctamente a todas las instancias de train (por eso accuracy de train aumenta a medida que incrementamos la altura máxima); sin embargo esto nos deja en un claro caso de overfitting, lo cual se evidencia al ver que a pesar de una mejora sustancial en la accuracy de train, la accuracy de validation no solo no mejora sino que empeora. \n",
        "A modo de conclusion podemos afirmar que aumentar la altura maxima de los arboles no solo va a resultar mas costoso computacionalmente sino que va a terminar por empeorar nuestro algoritmo."
      ],
      "metadata": {
        "id": "eFwqE-QFe1XG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5NbXkrMVYdZ"
      },
      "source": [
        "## Ejercicio 3: Comparación de algoritmos\n",
        "\n",
        "\n",
        "Se pide explorar distintas combinaciones de algoritmos de aprendizaje con diferentes configuraciones de manera de buscar la performance óptima. Para realizar la experimentación utilizar [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html). Como métrica de performance usar el área bajo la curva (AUC ROC) resultante de 5-fold cross-validation. \n",
        "\n",
        "Algoritmos a probar: \n",
        "  - Árboles de decisión\n",
        "  - KNN (k-vecinos más cercanos)\n",
        "  - SVM (Support vector machine)\n",
        "  - LDA (Linear discriminant analysis)\n",
        "  - Naïve Bayes\n",
        "  \n",
        "Hiperparámetros: Revisar la documentación de cada uno para la búsqueda de combinaciones prometedoras. \n",
        "\n",
        "Documentación extra sobre [`Tuning hyper-parameters`](https://scikit-learn.org/stable/modules/grid_search.html), leer hasta 3.2.2.\n",
        "\n",
        "Se pide generar un reporte que contenga: \n",
        "\n",
        "1. Una descripción de las distintas combinaciones consideradas y su performance asociada (las que consideren relevantes, con al menos la mejor combinación para cada algoritmo). \n",
        "\n",
        "1. Una breve explicación de los factores que creen que produjeron dicho resultado. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Comparación de algoritmos con RandomizedSearchCV\n",
        "\n",
        "Algoritmos a probar:\n",
        "\n",
        "* Árboles de decisión (esto ya lo hicimos recien, buscamos mejores arboles con hiperparametros? Si, aca probamos mas hp)\n",
        "* KNN (k-vecinos más cercanos)\n",
        "* SVM (Support vector machine)\n",
        "* LDA (Linear discriminant analysis)\n",
        "* Naïve Bayes"
      ],
      "metadata": {
        "id": "1TLDbhXIZ4d-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "podemos tomar el test score global como el promedio de cada uno de los folds (esta mal pero no tan mal)"
      ],
      "metadata": {
        "id": "foGFEyu-6NVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "def fine_tune(X, y, classifier, model_name, grid, cv, scoring, objective):\n",
        "    print('\\nFine tuning {0}. Objective: {1}'.format(model_name, objective))\n",
        "\n",
        "    pipeline_clf = Pipeline([\n",
        "        ('scaler', preprocessing.StandardScaler()),\n",
        "        ('clf', classifier)\n",
        "        ])\n",
        "\n",
        "    # agrego lo de standarizar, creo que esto hizo que de un poco peor, ver si lo hacemos o no \n",
        "    random_search = RandomizedSearchCV(estimator=pipeline_clf, param_distributions=grid, n_jobs=-1, cv=cv, scoring=scoring, refit=objective)\n",
        "    random_result = random_search.fit(X, y)\n",
        "    print(\"Best score was : %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
        "    return random_result.best_estimator_\n",
        "      "
      ],
      "metadata": {
        "id": "zcXUzh2UCgGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier  \n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Se iniciailizan default porque despues se van variando los hiperparámetros\n",
        "classifiers_to_test = {\n",
        "    'Árbol de decisión': DecisionTreeClassifier(),\n",
        "    'KNN': KNeighborsClassifier(n_jobs=-1),\n",
        "    'SVM' : SVC(),\n",
        "    'LDA' : LDA(),\n",
        "    'Naïve Bayes': GaussianNB()\n",
        "}\n",
        "\n",
        "grids = dict()\n",
        "\n",
        "grids['Árbol de decisión'] = {\n",
        "    'clf__criterion': ['gini', 'entropy', 'log_loss'],\n",
        "    'clf__splitter': ['best', 'random'],\n",
        "    'clf__max_depth': [None, 10, 50, 100, 150, 200],\n",
        "    'clf__max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "grids['KNN'] = {\n",
        "    'clf__n_neighbors': range(5, 26, 5),\n",
        "    'clf__weights': ['uniform', 'distance'],\n",
        "    'clf__leaf_size': randint(20, 50),\n",
        "    'clf__p': [1, 2]\n",
        "}\n",
        "grids['SVM'] = {\n",
        "    'clf__C': [0.5, 1, 2],\n",
        "    'clf__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'clf__degree': [1, 2, 3]\n",
        "}\n",
        "grids['LDA'] = {\n",
        "    'clf__solver': ['lsqr', 'eigen'],\n",
        "    'clf__shrinkage': [None, 'auto', 0, 0.25, 0.5, 0.75, 1]\n",
        "}\n",
        "grids['Naïve Bayes'] = {\n",
        "    'clf__var_smoothing': uniform(1e-9, 1e-7)\n",
        "}\n",
        "\n",
        "# TODO Ver estos warnings jeje\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "best_classifier = dict()\n",
        "for clf_name, clf in classifiers_to_test.items():\n",
        "    # fine_tune devuelve el estimador con la mejor combinación entre las que se prueban, en el dict guardamos la mejor config para cada algoritmo\n",
        "    best_classifier[clf_name] = fine_tune(X_dev, y_dev, clf, clf_name, grids[clf_name], balanced_k_fold, scoring, objective='roc_auc')\n"
      ],
      "metadata": {
        "id": "ZDZZlMrB_y1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier"
      ],
      "metadata": {
        "id": "WUcjmEoab2tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp20KR3zVYdZ"
      },
      "source": [
        "## Ejercicio 4: \n",
        "### Diagnóstico Sesgo-Varianza.\n",
        "\n",
        "(no mirar hasta el 19 de Abril)\n",
        "\n",
        "En este punto, se pide inspeccionar dos de sus mejores modelos encontrados hasta ahora: la mejor configuración para modelo de tipo árbol de decisión, la mejor configuración para LDA y la mejor configuración para SVM. Para ello:\n",
        "\n",
        "1. Graficar curvas de complejidad para cada modelo (sólo SVM y árboles), variando la profundidad en el caso de árboles, y el hiperparámetro C en el caso de SVM. Diagnosticar cómo afectan al sesgo y a la varianza esos dos hiperparámetros.\n",
        "2. Graficar curvas de aprendizaje para cada modelo. En base a estas curvas, sacar conclusiones sobre si los algoritmos parecen haber alcanzado su límite, o bien si aumentar la cantidad de datos debería ayudar.\n",
        "3. Construir un modelo RandomForest con 200 árboles. Explorar para qué sirve el hiperparámetro max_features y cómo afecta a la performance del algoritmo mediante una curva de complejidad. Explicar por qué creen que se dieron los resultados obtenidos. Por último, graficar una curva de aprendizaje sobre los parámetros elegidos para determinar si sería útil o no conseguir más datos.\n",
        "\n",
        "\n",
        "**Atención**: Tener en cuenta que debemos seguir utilizando ROC AUC como métrica para estas curvas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4) ?"
      ],
      "metadata": {
        "id": "PuAcXdhFOCHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construir un modelo RandomForest con 200 árboles. Explorar para qué sirve el hiperparámetro max_features y cómo afecta a la performance del algoritmo mediante una curva de complejidad. Explicar por qué creen que se dieron los resultados obtenidos. Por último, graficar una curva de aprendizaje sobre los parámetros elegidos para determinar si sería útil o no conseguir más datos."
      ],
      "metadata": {
        "id": "ChWKL8rub2-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "max features = The number of features to consider when looking for the best split // \n",
        "n_estimators = cantidad de árboles "
      ],
      "metadata": {
        "id": "NVzDgA1ob5Pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "randomforest = RandomForestClassifier(n_estimators = 200)"
      ],
      "metadata": {
        "id": "PBS9a02Zaa42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "features = []\n",
        "tiempos_y = []\n",
        "scores = []\n",
        "\n",
        "# Probamos max_features de 1, 2, 3 ... 49\n",
        "for i in range(1, 50):\n",
        "  randomforest = RandomForestClassifier(n_estimators=200, max_features=i)\n",
        "  t0 = timeit.default_timer()\n",
        "  randomforest.fit(X_train, y_train)\n",
        "  t1 = timeit.default_timer()\n",
        "  features.append(i)\n",
        "  tiempos_y.append(t1-t0)\n",
        "  scores.append(randomforest.score(X_test, y_test))\n",
        "\n",
        "# Probamos max_features de 50, 60 ... 90\n",
        "for i in range(50, 100, 10):\n",
        "  randomforest = RandomForestClassifier(n_estimators=200, max_features=i)\n",
        "  t0 = timeit.default_timer()\n",
        "  randomforest.fit(X_train, y_train)\n",
        "  t1 = timeit.default_timer()\n",
        "  features.append(i)\n",
        "  tiempos_y.append(t1-t0)\n",
        "  scores.append(randomforest.score(X_test, y_test))\n",
        "\n",
        "# Probamos max_features de 100, 150, 200\n",
        "for i in range(100, 201, 50):\n",
        "  randomforest = RandomForestClassifier(n_estimators=200, max_features=i)\n",
        "  t0 = timeit.default_timer()\n",
        "  randomforest.fit(X_train, y_train)\n",
        "  t1 = timeit.default_timer()\n",
        "  features.append(i)\n",
        "  tiempos_y.append(t1-t0)\n",
        "  scores.append(randomforest.score(X_test, y_test))\n"
      ],
      "metadata": {
        "id": "KPMVuZt18jAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(features, tiempos_y)\n",
        "plt.xlabel(\"max_features\")\n",
        "plt.ylabel(\"Tiempo (s)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "0CBm9pdf0OiB",
        "outputId": "ca836be3-0931-4ec7-911b-45dd2c4d0a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A mayor número de `max_features`, mayor es el número de features tiene que fijarse el algoritmo para determinar cada nivel de los árboles por lo que tardará más tiempo en realizar este paso si el número de features a mirar es mayor.\n",
        "\n",
        "REVISAR/ESCRIBIR MEJOR"
      ],
      "metadata": {
        "id": "6iVghRVo8jAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(features, scores)\n",
        "plt.xlabel(\"max_features\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "Byt8M3je5nrc",
        "outputId": "9fb1715e-8d4b-4db8-dfe0-7484c33d47ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"El mejor accuracy parece ser para max_features={features[np.argmax(scores)]}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0bA69qp6EdG",
        "outputId": "3b4c4a2b-4c78-4938-a2bd-7b59eea95c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El mejor accuracy parece ser para max_features=41.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pesar de eso, el accuracy no parece ser muy alto. Considerando además que tenemos 500 datos para aprender decisiones sobre 200 features, creemos necesario tener más datos."
      ],
      "metadata": {
        "id": "hEQY9lak6z-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# quizas sea util al final\n",
        "\n",
        "def youden(fpr, tpr, thresholds):\n",
        "    optimal_idx = np.argmax(tpr - fpr)\n",
        "    return thresholds[optimal_idx]\n",
        "\n",
        "def validate_classifiers(classifiers, X_train, y_train, X_test, y_test):\n",
        "    for name, clf in classifiers.items():\n",
        "        print('Validation for {0}'.format(name))\n",
        "        pipeline_clf = make_pipeline(preprocessing.StandardScaler(), clf)\n",
        "        pipeline_clf.fit(X_train, y_train)\n",
        "        metrics.plot_roc_curve(pipeline_clf, X_test, y_test)\n",
        "        churn_probas = pipeline_clf.predict_proba(X_test)[:, 1]\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(y_test, churn_probas)\n",
        "        youden_score = youden(fpr, tpr, thresholds)\n",
        "        print('Youden spot ---> {0}'.format(youden_score))\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "hdg-VogFbZmI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}