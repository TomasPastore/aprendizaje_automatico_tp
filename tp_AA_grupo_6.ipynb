{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomasPastore/aprendizaje_automatico_tp/blob/main/tp_AA_grupo_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import timeit\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "2B-2tXYZSL3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lectura del dataset\n",
        "\n",
        "\n",
        "# Sorry quizas rompi algo , ceno y en un rato lo arreglo"
      ],
      "metadata": {
        "id": "Wve0SoH6-upT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn7Ktz_1R0zw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "outputId": "8916b2fa-b1f2-4079-f12b-aa5f4df2c506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     target\n",
            "0         1\n",
            "1         1\n",
            "2         1\n",
            "3         1\n",
            "5         1\n",
            "..      ...\n",
            "483       1\n",
            "490       1\n",
            "491       1\n",
            "497       1\n",
            "499       1\n",
            "\n",
            "[154 rows x 1 columns]\n",
            "\n",
            " Features\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         v000      v001      v002      v003      v004      v005       v006  \\\n",
              "0    0.203777 -7.278026  2.756077  0.412740 -0.116626  0.414236   6.218588   \n",
              "1    1.084936  0.328886  4.545345  0.678987  0.003042 -0.807901 -13.653907   \n",
              "2    0.769527 -1.213339 -1.821305 -0.816333  3.059691 -0.583517  22.961234   \n",
              "3   -0.094123 -0.567694  1.747513  0.033398  7.415277 -0.756049  -1.021780   \n",
              "4    0.116567 -1.551208  9.343513 -1.785618 -2.651805  0.955870  -0.952141   \n",
              "..        ...       ...       ...       ...       ...       ...        ...   \n",
              "495 -0.288139 -1.396761 -4.263799  0.749690  1.721721 -0.344043  19.469950   \n",
              "496  0.153794 -1.877765  0.514750  3.191452  2.515170  0.214678   1.100869   \n",
              "497  0.128327 -2.151517 -6.010139 -5.710254 -2.606002 -0.326701  -3.537265   \n",
              "498  0.907801  2.899501 -2.170869  1.386165  4.658550  0.172423   2.034290   \n",
              "499  0.173000  1.544216  7.862991  2.611334 -3.852684 -0.453429  30.162525   \n",
              "\n",
              "         v007      v008      v009  ...       v190       v191      v192  \\\n",
              "0    0.018764  0.209555  0.005660  ...  -8.551783  -5.323863  2.004479   \n",
              "1   -0.654958 -0.860854 -1.017529  ...   1.195129 -20.574463  0.119288   \n",
              "2   -1.034725 -0.039125  0.983415  ...   2.926464  14.608653 -0.456923   \n",
              "3   -0.662921 -0.671345 -0.159661  ...   4.750111  21.559404  0.188952   \n",
              "4   -0.854849 -0.679621  0.682699  ...   0.364826  24.729498 -0.585663   \n",
              "..        ...       ...       ...  ...        ...        ...       ...   \n",
              "495  0.662457  0.557387 -0.190842  ...   1.589264  17.684302 -1.333075   \n",
              "496 -0.641812 -0.192485  2.340703  ...  -0.849789 -12.417970  0.906713   \n",
              "497 -0.786013 -0.985565  0.120138  ... -10.669278  -7.494708  0.520567   \n",
              "498  0.563519 -1.294684  0.853006  ...   0.691517 -18.558853  1.667956   \n",
              "499 -0.319517 -0.718359  1.447191  ...  -5.883870  28.225737  0.104841   \n",
              "\n",
              "         v193      v194      v195      v196      v197      v198      v199  \n",
              "0   -0.065859 -0.877748  0.221820  0.103884 -0.219372  2.179068  0.578645  \n",
              "1    0.505041  0.922128  0.405464  1.886947  0.407544  1.431193  0.159015  \n",
              "2   -0.647099 -0.565453 -0.137190 -0.232586 -1.420808 -0.843064  0.274254  \n",
              "3    0.137507  1.186905  0.955207  0.589803  1.509390  0.992935  1.875483  \n",
              "4   -1.551728  0.239188 -0.882897  0.129474  0.019597 -0.322608  0.302670  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "495  0.388253  1.314865  0.244731 -0.051043  0.768067 -1.622517 -0.276086  \n",
              "496 -0.066838  1.210734  1.491540  1.586784 -0.445346  1.701997 -0.326600  \n",
              "497 -1.523764  0.714171  0.222749 -0.126531 -0.074166 -0.752975 -1.750938  \n",
              "498  0.697122  2.236943 -0.629723  0.969926 -1.121823 -0.413634  0.321612  \n",
              "499 -0.357252  0.055396  0.894034  0.415548  0.908002 -0.172811 -0.364571  \n",
              "\n",
              "[500 rows x 200 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa7c2bb5-3990-4acc-aa14-384ad09bf9c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v000</th>\n",
              "      <th>v001</th>\n",
              "      <th>v002</th>\n",
              "      <th>v003</th>\n",
              "      <th>v004</th>\n",
              "      <th>v005</th>\n",
              "      <th>v006</th>\n",
              "      <th>v007</th>\n",
              "      <th>v008</th>\n",
              "      <th>v009</th>\n",
              "      <th>...</th>\n",
              "      <th>v190</th>\n",
              "      <th>v191</th>\n",
              "      <th>v192</th>\n",
              "      <th>v193</th>\n",
              "      <th>v194</th>\n",
              "      <th>v195</th>\n",
              "      <th>v196</th>\n",
              "      <th>v197</th>\n",
              "      <th>v198</th>\n",
              "      <th>v199</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.203777</td>\n",
              "      <td>-7.278026</td>\n",
              "      <td>2.756077</td>\n",
              "      <td>0.412740</td>\n",
              "      <td>-0.116626</td>\n",
              "      <td>0.414236</td>\n",
              "      <td>6.218588</td>\n",
              "      <td>0.018764</td>\n",
              "      <td>0.209555</td>\n",
              "      <td>0.005660</td>\n",
              "      <td>...</td>\n",
              "      <td>-8.551783</td>\n",
              "      <td>-5.323863</td>\n",
              "      <td>2.004479</td>\n",
              "      <td>-0.065859</td>\n",
              "      <td>-0.877748</td>\n",
              "      <td>0.221820</td>\n",
              "      <td>0.103884</td>\n",
              "      <td>-0.219372</td>\n",
              "      <td>2.179068</td>\n",
              "      <td>0.578645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.084936</td>\n",
              "      <td>0.328886</td>\n",
              "      <td>4.545345</td>\n",
              "      <td>0.678987</td>\n",
              "      <td>0.003042</td>\n",
              "      <td>-0.807901</td>\n",
              "      <td>-13.653907</td>\n",
              "      <td>-0.654958</td>\n",
              "      <td>-0.860854</td>\n",
              "      <td>-1.017529</td>\n",
              "      <td>...</td>\n",
              "      <td>1.195129</td>\n",
              "      <td>-20.574463</td>\n",
              "      <td>0.119288</td>\n",
              "      <td>0.505041</td>\n",
              "      <td>0.922128</td>\n",
              "      <td>0.405464</td>\n",
              "      <td>1.886947</td>\n",
              "      <td>0.407544</td>\n",
              "      <td>1.431193</td>\n",
              "      <td>0.159015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.769527</td>\n",
              "      <td>-1.213339</td>\n",
              "      <td>-1.821305</td>\n",
              "      <td>-0.816333</td>\n",
              "      <td>3.059691</td>\n",
              "      <td>-0.583517</td>\n",
              "      <td>22.961234</td>\n",
              "      <td>-1.034725</td>\n",
              "      <td>-0.039125</td>\n",
              "      <td>0.983415</td>\n",
              "      <td>...</td>\n",
              "      <td>2.926464</td>\n",
              "      <td>14.608653</td>\n",
              "      <td>-0.456923</td>\n",
              "      <td>-0.647099</td>\n",
              "      <td>-0.565453</td>\n",
              "      <td>-0.137190</td>\n",
              "      <td>-0.232586</td>\n",
              "      <td>-1.420808</td>\n",
              "      <td>-0.843064</td>\n",
              "      <td>0.274254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.094123</td>\n",
              "      <td>-0.567694</td>\n",
              "      <td>1.747513</td>\n",
              "      <td>0.033398</td>\n",
              "      <td>7.415277</td>\n",
              "      <td>-0.756049</td>\n",
              "      <td>-1.021780</td>\n",
              "      <td>-0.662921</td>\n",
              "      <td>-0.671345</td>\n",
              "      <td>-0.159661</td>\n",
              "      <td>...</td>\n",
              "      <td>4.750111</td>\n",
              "      <td>21.559404</td>\n",
              "      <td>0.188952</td>\n",
              "      <td>0.137507</td>\n",
              "      <td>1.186905</td>\n",
              "      <td>0.955207</td>\n",
              "      <td>0.589803</td>\n",
              "      <td>1.509390</td>\n",
              "      <td>0.992935</td>\n",
              "      <td>1.875483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.116567</td>\n",
              "      <td>-1.551208</td>\n",
              "      <td>9.343513</td>\n",
              "      <td>-1.785618</td>\n",
              "      <td>-2.651805</td>\n",
              "      <td>0.955870</td>\n",
              "      <td>-0.952141</td>\n",
              "      <td>-0.854849</td>\n",
              "      <td>-0.679621</td>\n",
              "      <td>0.682699</td>\n",
              "      <td>...</td>\n",
              "      <td>0.364826</td>\n",
              "      <td>24.729498</td>\n",
              "      <td>-0.585663</td>\n",
              "      <td>-1.551728</td>\n",
              "      <td>0.239188</td>\n",
              "      <td>-0.882897</td>\n",
              "      <td>0.129474</td>\n",
              "      <td>0.019597</td>\n",
              "      <td>-0.322608</td>\n",
              "      <td>0.302670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>-0.288139</td>\n",
              "      <td>-1.396761</td>\n",
              "      <td>-4.263799</td>\n",
              "      <td>0.749690</td>\n",
              "      <td>1.721721</td>\n",
              "      <td>-0.344043</td>\n",
              "      <td>19.469950</td>\n",
              "      <td>0.662457</td>\n",
              "      <td>0.557387</td>\n",
              "      <td>-0.190842</td>\n",
              "      <td>...</td>\n",
              "      <td>1.589264</td>\n",
              "      <td>17.684302</td>\n",
              "      <td>-1.333075</td>\n",
              "      <td>0.388253</td>\n",
              "      <td>1.314865</td>\n",
              "      <td>0.244731</td>\n",
              "      <td>-0.051043</td>\n",
              "      <td>0.768067</td>\n",
              "      <td>-1.622517</td>\n",
              "      <td>-0.276086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>0.153794</td>\n",
              "      <td>-1.877765</td>\n",
              "      <td>0.514750</td>\n",
              "      <td>3.191452</td>\n",
              "      <td>2.515170</td>\n",
              "      <td>0.214678</td>\n",
              "      <td>1.100869</td>\n",
              "      <td>-0.641812</td>\n",
              "      <td>-0.192485</td>\n",
              "      <td>2.340703</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.849789</td>\n",
              "      <td>-12.417970</td>\n",
              "      <td>0.906713</td>\n",
              "      <td>-0.066838</td>\n",
              "      <td>1.210734</td>\n",
              "      <td>1.491540</td>\n",
              "      <td>1.586784</td>\n",
              "      <td>-0.445346</td>\n",
              "      <td>1.701997</td>\n",
              "      <td>-0.326600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>0.128327</td>\n",
              "      <td>-2.151517</td>\n",
              "      <td>-6.010139</td>\n",
              "      <td>-5.710254</td>\n",
              "      <td>-2.606002</td>\n",
              "      <td>-0.326701</td>\n",
              "      <td>-3.537265</td>\n",
              "      <td>-0.786013</td>\n",
              "      <td>-0.985565</td>\n",
              "      <td>0.120138</td>\n",
              "      <td>...</td>\n",
              "      <td>-10.669278</td>\n",
              "      <td>-7.494708</td>\n",
              "      <td>0.520567</td>\n",
              "      <td>-1.523764</td>\n",
              "      <td>0.714171</td>\n",
              "      <td>0.222749</td>\n",
              "      <td>-0.126531</td>\n",
              "      <td>-0.074166</td>\n",
              "      <td>-0.752975</td>\n",
              "      <td>-1.750938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0.907801</td>\n",
              "      <td>2.899501</td>\n",
              "      <td>-2.170869</td>\n",
              "      <td>1.386165</td>\n",
              "      <td>4.658550</td>\n",
              "      <td>0.172423</td>\n",
              "      <td>2.034290</td>\n",
              "      <td>0.563519</td>\n",
              "      <td>-1.294684</td>\n",
              "      <td>0.853006</td>\n",
              "      <td>...</td>\n",
              "      <td>0.691517</td>\n",
              "      <td>-18.558853</td>\n",
              "      <td>1.667956</td>\n",
              "      <td>0.697122</td>\n",
              "      <td>2.236943</td>\n",
              "      <td>-0.629723</td>\n",
              "      <td>0.969926</td>\n",
              "      <td>-1.121823</td>\n",
              "      <td>-0.413634</td>\n",
              "      <td>0.321612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>0.173000</td>\n",
              "      <td>1.544216</td>\n",
              "      <td>7.862991</td>\n",
              "      <td>2.611334</td>\n",
              "      <td>-3.852684</td>\n",
              "      <td>-0.453429</td>\n",
              "      <td>30.162525</td>\n",
              "      <td>-0.319517</td>\n",
              "      <td>-0.718359</td>\n",
              "      <td>1.447191</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.883870</td>\n",
              "      <td>28.225737</td>\n",
              "      <td>0.104841</td>\n",
              "      <td>-0.357252</td>\n",
              "      <td>0.055396</td>\n",
              "      <td>0.894034</td>\n",
              "      <td>0.415548</td>\n",
              "      <td>0.908002</td>\n",
              "      <td>-0.172811</td>\n",
              "      <td>-0.364571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 200 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa7c2bb5-3990-4acc-aa14-384ad09bf9c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa7c2bb5-3990-4acc-aa14-384ad09bf9c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa7c2bb5-3990-4acc-aa14-384ad09bf9c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "url = 'https://raw.githubusercontent.com/aprendizaje-automatico-dc-uba-ar/material/main/tp/01_aprendizaje_supervisado/datos/minions_publicos.csv'\n",
        "minions_dataset = pd.read_csv(url)\n",
        "\n",
        "y = minions_dataset.iloc[:,-1:]\n",
        "print(y[y[\"target\"] == 1])\n",
        "\n",
        "del minions_dataset[minions_dataset.columns[-1]]\n",
        "print(\"\\n Features\")\n",
        "minions_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto nos indica que hay 154 de clase positiva y el resto de clase negativa. Es decir, está desbalanceado en aproximadamente 30/70. Tenemos que tener en cuenta entonces esto a la hora de splitear los datos."
      ],
      "metadata": {
        "id": "5eX-IzBzwcaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Separación de datos\n",
        "\n",
        "Para la separación de datos de evaluación, lo primero que tuvimos en cuenta fue evaluar la distribucion de etiquetas de los minions entrevistados. Al revisar esto notamos que hay un desbalance entre minions que fueron aceptados vs aquellos que no (aproximadamente fueron aceptados el 30% de los postulantes). Por lo tanto es primordial que mantengamos la proporción entre estas dos clases cuando hagamos los _k-folds_, ya que de no realizarlo nuestro predictor no se entrenaría con las proporciones correctas de los datos. \n",
        "\n",
        "En segundo lugar tenemos que tener en cuenta la cantidad de candidatos que tenemos. Solamente 500 postulados resulta una base de datos más bien reducida, por lo que no tenemos margen a la hora de decidir nuestra estrategia a la hora de separación de datos. Lo que nuestro grupo propone es realizar una separación del 10% para utilizar en la etapa de evaluación final, manteniendo el 90% restante para el desarrollo de nuestros modelos (todo esto haciendo _stratified split_ para que el desbalance de datos no nos perjudique a futuro).\n",
        "\n",
        "#########################\n",
        "Revisar juntos, cuando hacemos el train_test_split se elije al azar, se mantiene las proporciones de las clases pero se hace al azar, no estamos considerando el desbalanceo. mas datos para eval??"
      ],
      "metadata": {
        "id": "mxZBE44sBV78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_dev, X_eval, y_dev, y_eval = train_test_split(minions_dataset, y, shuffle=True, random_state=4, test_size=0.1) # quedan 15 positivos para eval\n",
        "\n",
        "print(f\"X_train dimensión: {X_dev.shape}\")\n",
        "print(f\"y_train dimensión: {y_dev.shape}\")\n",
        "\n",
        "print(f\"X_test dimensión: {X_eval.shape}\")\n",
        "print(f\"y_test dimensión: {y_eval.shape}\")\n"
      ],
      "metadata": {
        "id": "nd48vRPt3KU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be125475-e051-4d68-f1e4-0bb741bc3cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train dimensión: (450, 200)\n",
            "y_train dimensión: (450, 1)\n",
            "X_test dimensión: (50, 200)\n",
            "y_test dimensión: (50, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Construcción de modelos"
      ],
      "metadata": {
        "id": "6G3jEonGDxuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1) Árbol default con max_height 3"
      ],
      "metadata": {
        "id": "PGUSW2t3UCF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "arbol_gini_3 = DecisionTreeClassifier(max_depth=3)"
      ],
      "metadata": {
        "id": "qPq5DoemUCbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2) Iteradores de cross validation"
      ],
      "metadata": {
        "id": "4aIzNpJyNPZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
        "\n",
        "balanced_k_fold = StratifiedKFold(n_splits=5)\n",
        "\n",
        "# Validar si podemos usar esto porque el enunciado dice k fold\n",
        "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=4)\n",
        "\n",
        "X_train_cv = []\n",
        "y_train_cv = []\n",
        "X_test_cv = []\n",
        "y_test_cv = []\n",
        "\n",
        "for train_index, test_index in sss.split(X_dev, y_dev):\n",
        "    X_train = X_dev.iloc[train_index]\n",
        "    X_test = X_dev.iloc[test_index]\n",
        "    y_train = y_dev.iloc[train_index]\n",
        "    y_test = y_dev.iloc[test_index]\n",
        "    \n",
        "    X_train_cv.append(X_train)\n",
        "    X_test_cv.append(X_test)\n",
        "    y_train_cv.append(y_train)\n",
        "    y_test_cv.append(y_test)\n"
      ],
      "metadata": {
        "id": "LVHBdOaASR73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2) Métricas"
      ],
      "metadata": {
        "id": "EnSjS6fiQi3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Scoring metrics\n",
        "\n",
        "def tn(y, y_pred): return metrics.confusion_matrix(y, y_pred)[0, 0];\n",
        "def fp(y, y_pred): return metrics.confusion_matrix(y, y_pred)[0, 1];\n",
        "def fn(y, y_pred): return metrics.confusion_matrix(y, y_pred)[1, 0];\n",
        "def tp(y, y_pred): return metrics.confusion_matrix(y, y_pred)[1, 1];\n",
        "def specificity(y, y_pred): return tn(y, y_pred)/(tn(y, y_pred) + fp(y,y_pred));\n",
        "def precision(y, y_pred): return tp(y, y_pred)/(tp(y, y_pred) + fp(y, y_pred));\n",
        "def recall(y, y_pred): return tp(y, y_pred)/(tp(y, y_pred) + fn(y, y_pred));\n",
        "def f1(y, y_pred): return 2 * precision(y, y_pred) * recall(y, y_pred) / (precision(y, y_pred) + recall(y_pred))\n",
        "\n",
        "scoring = {#'precision': metrics.make_scorer(precision), \n",
        "           #'recall': metrics.make_scorer(recall),\n",
        "           #'specificity': metrics.make_scorer(specificity),\n",
        "           #'tp': metrics.make_scorer(tp),\n",
        "           #'tn': metrics.make_scorer(tn),\n",
        "           #'fp': metrics.make_scorer(fp),\n",
        "           #'fn': metrics.make_scorer(fn),\n",
        "           #'f1_score': metrics.make_scorer(f1),\n",
        "           'roc_auc': metrics.make_scorer(metrics.roc_auc_score),\n",
        "           'accuracy': 'accuracy'\n",
        "           }\n"
      ],
      "metadata": {
        "id": "SBOIPn3sQ97s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2) Árbol default (gini) altura 3 + Crossvalidation K=5 + Accuracy y AUC \n",
        "\n",
        "Integramos las 3 celdas anteriores para correr los folds y calcular las metricas para un classificador"
      ],
      "metadata": {
        "id": "Mkv4DgcVNa19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Runs crossvalidation with one fixed configuration of parameters.\n",
        "# for each classifier in the values of classifiers dictionary (param)\n",
        "# scoring is a dictionary with the metrics we want to calculate accross iterations\n",
        "# cv is a cross validation iterator\n",
        "\n",
        "# TODO modificar para que imprima el global, el promedio etc, cada fold\n",
        "def cv_with_metrics(classifiers, X, y, scoring, cv):\n",
        "    for clf_name, clf in classifiers.items():\n",
        "        print('Crossvalidating with {0}'.format(clf_name))\n",
        "        pipeline_clf = make_pipeline(preprocessing.StandardScaler(), clf)\n",
        "        cv_results = cross_validate(pipeline_clf, X, y=y, scoring=scoring, cv=cv, n_jobs=-1)\n",
        "        print('Scoring mean across folds for {0}...'.format(clf_name))\n",
        "        for key, v in cv_results.items():\n",
        "            if 'test' in key:\n",
        "                print('\\t{k} --> {m}'.format(k=key, m=np.mean(cv_results[key])))\n"
      ],
      "metadata": {
        "id": "2DNwIAfmZ-Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corremos el K fold cross validation para una configuracion fija\n",
        "classifiers_to_test = {'Árbol de Decisión <default, max_h=3 > ': arbol_gini_3 }\n",
        "cv_with_metrics(classifiers_to_test, X_dev, y_dev, scoring, cv=balanced_k_fold)\n"
      ],
      "metadata": {
        "id": "TiPuv3ZxXF8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7793ca0c-12c6-4ceb-f5dc-c361731408f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crossvalidating with Árbol de Decisión <default, max_h=3 > \n",
            "Scoring mean across folds for Árbol de Decisión <default, max_h=3 > ...\n",
            "\ttest_roc_auc --> 0.5754949650110941\n",
            "\ttest_accuracy --> 0.6644444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resultados**<table>\n",
        "      <thead>\n",
        "      <tr>\n",
        "      <th align=\"center\">Permutación</th>\n",
        "      <th>Accuracy (training)</th>\n",
        "      <th>Accuracy (validación)</th>\n",
        "      <th>AUC ROC (training)</th>\n",
        "      <th>AUC ROC (validación)</th>\n",
        "      </tr>\n",
        "      </thead>\n",
        "      <tbody>\n",
        "      <tr>\n",
        "      <td align=\"center\">1</td>\n",
        "      <td>0,769</td>\n",
        "      <td>0.722</td>\n",
        "      <td>0.815</td>\n",
        "      <td>0.759</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">2</td>\n",
        "      <td>0.806</td>\n",
        "      <td>0.667</td>\n",
        "      <td>0.774</td>\n",
        "      <td>0.622</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">3</td>\n",
        "      <td>0.841</td>\n",
        "      <td>0.689</td>\n",
        "      <td>0.837</td>\n",
        "      <td>0.614</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">4</td>\n",
        "      <td>0.786</td>\n",
        "      <td>0.6</td>\n",
        "      <td>0.757</td>\n",
        "      <td>0.493</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">5</td>\n",
        "      <td>0.839</td>\n",
        "      <td>0.711</td>\n",
        "      <td>0.841</td>\n",
        "      <td>0.655</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">Global</td>\n",
        "      <td>0.678</td>\n",
        "      <td>0.808</td>\n",
        "      <td>0.817</td>\n",
        "      <td>0.629</td>\n",
        "      </tr>\n",
        "      </tbody>\n",
        "      </table>"
      ],
      "metadata": {
        "id": "CurMQznvQmTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.3) Parameter grid sobre el arbol"
      ],
      "metadata": {
        "id": "tTETHVB8NoEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# gini (default) con max depth 3, 5 e inf (default)\n",
        "# entropy con max depth 3, 5 e inf\n",
        "\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "def parameter_grid(grid):\n",
        "  param_grid = ParameterGrid(grid)\n",
        "  for config in param_grid:\n",
        "    "
      ],
      "metadata": {
        "id": "lIGbkdVsVkLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "BBB = 0\n",
        "CCC = 0\n",
        "DDD = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier(max_depth=3)\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  y_pred_test = arbol.predict(X_train_cv[i])\n",
        "  y_pred_cv.append(y_pred_test)\n",
        "\n",
        "  # print(y_pred)\n",
        "\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el train set: {arbol.score(X_train_cv[i], y_train_cv[i])}\")\n",
        "\n",
        "  auc_train = roc_auc_score(y_pred_test, y_train_cv[i])\n",
        "  print(\"AUC de la curva ROC sobre el train set:\", auc_train)\n",
        "\n",
        "\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  auc_test = roc_auc_score(y_pred, y_test_cv[i])\n",
        "  print(\"AUC de la curva ROC sobre el test set:\", auc_test)\n",
        "\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  BBB += auc_test\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "  DDD += auc_train\n",
        "\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"AUC promedio de test:\", BBB/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)\n",
        "print(\"AUC promedio de train:\", DDD/5)\n",
        "\n"
      ],
      "metadata": {
        "id": "zrk7My-dVtKv",
        "outputId": "72b7f347-d080-45d9-bd09-b813bcfb96b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy sobre el train set: 0.7694444444444445\n",
            "AUC de la curva ROC sobre el train set: 0.875\n",
            "Accuracy sobre el test set: 0.7111111111111111\n",
            "AUC de la curva ROC sobre el test set: 0.6722560975609756\n",
            "Accuracy sobre el train set: 0.8055555555555556\n",
            "AUC de la curva ROC sobre el train set: 0.7742650712947743\n",
            "Accuracy sobre el test set: 0.6666666666666666\n",
            "AUC de la curva ROC sobre el test set: 0.6223060344827586\n",
            "Accuracy sobre el train set: 0.8416666666666667\n",
            "AUC de la curva ROC sobre el train set: 0.8372960168450605\n",
            "Accuracy sobre el test set: 0.6888888888888889\n",
            "AUC de la curva ROC sobre el test set: 0.6148648648648648\n",
            "Accuracy sobre el train set: 0.7861111111111111\n",
            "AUC de la curva ROC sobre el train set: 0.7569875776397517\n",
            "Accuracy sobre el test set: 0.6\n",
            "AUC de la curva ROC sobre el test set: 0.4928571428571429\n",
            "Accuracy sobre el train set: 0.8388888888888889\n",
            "AUC de la curva ROC sobre el train set: 0.8408058372722682\n",
            "Accuracy sobre el test set: 0.7111111111111111\n",
            "AUC de la curva ROC sobre el test set: 0.6550802139037433\n",
            "accuracy promedio de test: 0.6755555555555556\n",
            "AUC promedio de test: 0.6114728707338971\n",
            "accuracy promedio de train: 0.8083333333333333\n",
            "AUC promedio de train: 0.8168709006103709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "CCC = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier(max_depth=5)\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  # print(y_pred)\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)"
      ],
      "metadata": {
        "id": "4Dl6YZHaM0bU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3566dd9-41c2-46d3-c4b7-c08ff7c6d3b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy sobre el test set: 0.7333333333333333\n",
            "Accuracy sobre el test set: 0.6444444444444445\n",
            "Accuracy sobre el test set: 0.6777777777777778\n",
            "Accuracy sobre el test set: 0.6111111111111112\n",
            "Accuracy sobre el test set: 0.6777777777777778\n",
            "accuracy promedio de test: 0.6688888888888889\n",
            "accuracy promedio de train: 0.9122222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "CCC = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier()\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  # print(y_pred)\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZZobgYrVVJX",
        "outputId": "18c7ae6a-dc0b-45b0-e4a7-3754d5780ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy sobre el test set: 0.6888888888888889\n",
            "Accuracy sobre el test set: 0.6555555555555556\n",
            "Accuracy sobre el test set: 0.6666666666666666\n",
            "Accuracy sobre el test set: 0.6333333333333333\n",
            "Accuracy sobre el test set: 0.6777777777777778\n",
            "accuracy promedio de test: 0.6644444444444444\n",
            "accuracy promedio de train: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "CCC = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  # print(y_pred)\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPswfptgWRj9",
        "outputId": "ef91c217-c2dd-4408-abee-3a7346035261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy sobre el test set: 0.7111111111111111\n",
            "Accuracy sobre el test set: 0.6222222222222222\n",
            "Accuracy sobre el test set: 0.6888888888888889\n",
            "Accuracy sobre el test set: 0.6\n",
            "Accuracy sobre el test set: 0.6444444444444445\n",
            "accuracy promedio de test: 0.6533333333333333\n",
            "accuracy promedio de train: 0.7861111111111111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "CCC = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  # print(y_pred)\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7MCZrIuWRsg",
        "outputId": "d59a2ed8-aeba-42be-9db4-374efafb04e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy sobre el test set: 0.6555555555555556\n",
            "Accuracy sobre el test set: 0.6111111111111112\n",
            "Accuracy sobre el test set: 0.7\n",
            "Accuracy sobre el test set: 0.6444444444444445\n",
            "Accuracy sobre el test set: 0.6333333333333333\n",
            "accuracy promedio de test: 0.6488888888888888\n",
            "accuracy promedio de train: 0.8983333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "CCC = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier(criterion='entropy')\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  # print(y_pred)\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju7mq4bFWRyW",
        "outputId": "94f8804f-bcdb-4016-9f39-44dbe2e892ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy sobre el test set: 0.6111111111111112\n",
            "Accuracy sobre el test set: 0.6222222222222222\n",
            "Accuracy sobre el test set: 0.6666666666666666\n",
            "Accuracy sobre el test set: 0.6555555555555556\n",
            "Accuracy sobre el test set: 0.5888888888888889\n",
            "accuracy promedio de test: 0.6288888888888888\n",
            "accuracy promedio de train: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table>\n",
        "   <thead>\n",
        "   <tr>\n",
        "   <th align=\"center\">Altura máxima</th>\n",
        "   <th align=\"center\">Criterio de corte</th>\n",
        "   <th>Accuracy (training)</th>\n",
        "   <th>Accuracy (validación)</th>\n",
        "   </tr>\n",
        "   </thead>\n",
        "   <tbody><tr>\n",
        "   <td align=\"center\">3</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td>0.8</td>\n",
        "   <td>0.67</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">5</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td>0.91</td>\n",
        "   <td>0.67</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">Infinito</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td>1.0</td>\n",
        "   <td>0.67</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">3</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td>0.78</td>\n",
        "   <td>0.64</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">5</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td>0.89</td>\n",
        "   <td>0.64</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">Infinito</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td>1.0</td>\n",
        "   <td>0.63</td>\n",
        "   </tr>\n",
        "   </tbody></table>"
      ],
      "metadata": {
        "id": "XKxTFERbc3xQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "conclusiones: (a checkear si estan bien calculadas las métricas, siento que tendrian que dar otra cosa) Podemos observar que un aumento en la altura máxima de los arboles no se condice con una mejora en la performance en la etapa de validacion. Esto se debe a que si los arboles tienen altura infinita van a asegurarse de que podamos clasificar correctamente a todas las instancias de train (por eso accuracy de train aumenta a medida que incrementamos la altura máxima); sin embargo esto nos deja en un claro caso de overfitting, lo cual se evidencia al ver que a pesar de una mejora sustancial en la accuracy de train, la accuracy de validation no solo no mejora sino que empeora. \n",
        "A modo de conclusion podemos afirmar que aumentar la altura maxima de los arboles no solo va a resultar mas costoso computacionalmente sino que va a terminar por empeorar nuestro algoritmo."
      ],
      "metadata": {
        "id": "eFwqE-QFe1XG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Comparación de algoritmos con RandomizedSearchCV\n",
        "\n",
        "Algoritmos a probar:\n",
        "\n",
        "* Árboles de decisión (esto ya lo hicimos recien, buscamos mejores arboles con hiperparametros? Si, aca probamos mas hp)\n",
        "* KNN (k-vecinos más cercanos)\n",
        "* SVM (Support vector machine)\n",
        "* LDA (Linear discriminant analysis)\n",
        "* Naïve Bayes"
      ],
      "metadata": {
        "id": "1TLDbhXIZ4d-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "podemos tomar el test score global como el promedio de cada uno de los folds (esta mal pero no tan mal)"
      ],
      "metadata": {
        "id": "foGFEyu-6NVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "def fine_tune(X, y, classifier, model_name, grid, cv, scoring, objective, random=True):\n",
        "    print('\\nFine tuning {0}. Objective: {1}'.format(model_name, objective))\n",
        "\n",
        "    if random:\n",
        "      random_search = RandomizedSearchCV(estimator=classifier, param_distributions=grid, n_jobs=-1, cv=cv, scoring=scoring, refit=objective)\n",
        "      random_result = random_search.fit(X, y)\n",
        "      print(\"Best score was : %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
        "      return random_result.best_estimator_\n",
        "    else:\n",
        "      # TODO borrar si estan de acuerdo, total dice q no se puede usar\n",
        "      grid_search = GridSearchCV(estimator=classifier, param_grid=grid, n_jobs=-1, cv=cv, scoring=scoring, refit=objective)\n",
        "      grid_result = grid_search.fit(X, y)\n",
        "      print(\"Best score was : %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "      return grid_result.best_estimator_"
      ],
      "metadata": {
        "id": "zcXUzh2UCgGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier  \n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Se iniciailizan default porque despues se van variando los hiperparámetros\n",
        "classifiers_to_test = {\n",
        "    'Árbol de decisión': DecisionTreeClassifier(),\n",
        "    'KNN': KNeighborsClassifier(n_jobs=-1),\n",
        "    'SVM' : SVC(),\n",
        "    'LDA' : LDA(),\n",
        "    'Naïve Bayes': GaussianNB()\n",
        "}\n",
        "\n",
        "grids = dict()\n",
        "\n",
        "grids['Árbol de decisión'] = {\n",
        "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'max_depth': [None, 10, 50, 100, 150, 200],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "grids['KNN'] = {\n",
        "    'n_neighbors': range(5, 26, 5),\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'leaf_size': randint(20, 50),\n",
        "    'p': [1, 2]\n",
        "}\n",
        "grids['SVM'] = {\n",
        "    'C': [0.5, 1, 2],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'degree': [1, 2, 3]\n",
        "}\n",
        "grids['LDA'] = {\n",
        "    'solver': ['lsqr', 'eigen'],\n",
        "    'shrinkage': [None, 'auto', 0, 0.25, 0.5, 0.75, 1]\n",
        "}\n",
        "grids['Naïve Bayes'] = {\n",
        "    'var_smoothing': uniform(1e-9, 1e-7)\n",
        "}\n",
        "\n",
        "# TODO Ver estos warnings jeje\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "best_classifier = dict()\n",
        "for clf_name, clf in classifiers_to_test.items():\n",
        "    # fine_tune devuelve el estimador con la mejor combinación entre las que se prueban, en el dict guardamos la mejor config para cada algoritmo\n",
        "    best_classifier[clf_name] = fine_tune(X_dev, y_dev, clf, clf_name, grids[clf_name], balanced_k_fold, scoring, objective='roc_auc')\n"
      ],
      "metadata": {
        "id": "ZDZZlMrB_y1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc92724-1eb6-4a43-c37b-5b4ea5187ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fine tuning Árbol de decisión. Objective: roc_auc\n",
            "Best score was : 0.609554 using {'splitter': 'random', 'max_features': 'log2', 'max_depth': 50, 'criterion': 'gini'}\n",
            "\n",
            "Fine tuning KNN. Objective: roc_auc\n",
            "Best score was : 0.686973 using {'leaf_size': 46, 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n",
            "\n",
            "Fine tuning SVM. Objective: roc_auc\n",
            "Best score was : 0.708551 using {'kernel': 'rbf', 'degree': 2, 'C': 1}\n",
            "\n",
            "Fine tuning LDA. Objective: roc_auc\n",
            "Best score was : 0.743834 using {'solver': 'lsqr', 'shrinkage': 0.5}\n",
            "\n",
            "Fine tuning Naïve Bayes. Objective: roc_auc\n",
            "Best score was : 0.674445 using {'var_smoothing': 2.2191999701110953e-08}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier"
      ],
      "metadata": {
        "id": "WUcjmEoab2tK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb44cfb-b7ed-464a-9bc5-fb00d8cf7785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Árbol de decisión': DecisionTreeClassifier(max_depth=50, max_features='log2', splitter='random'),\n",
              " 'KNN': KNeighborsClassifier(leaf_size=46, n_jobs=-1, p=1),\n",
              " 'SVM': SVC(C=1, degree=2),\n",
              " 'LDA': LinearDiscriminantAnalysis(shrinkage=0.5, solver='lsqr'),\n",
              " 'Naïve Bayes': GaussianNB(var_smoothing=2.2191999701110953e-08)}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construir un modelo RandomForest con 200 árboles. Explorar para qué sirve el hiperparámetro max_features y cómo afecta a la performance del algoritmo mediante una curva de complejidad. Explicar por qué creen que se dieron los resultados obtenidos. Por último, graficar una curva de aprendizaje sobre los parámetros elegidos para determinar si sería útil o no conseguir más datos."
      ],
      "metadata": {
        "id": "ChWKL8rub2-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "max features = The number of features to consider when looking for the best split // \n",
        "n_estimators = cantidad de árboles "
      ],
      "metadata": {
        "id": "NVzDgA1ob5Pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "randomforest = RandomForestClassifier(randomforest = RandomForestClassifier(n_estimators = 200))"
      ],
      "metadata": {
        "id": "PBS9a02Zaa42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quizas sea util al final\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def youden(fpr, tpr, thresholds):\n",
        "    optimal_idx = np.argmax(tpr - fpr)\n",
        "    return thresholds[optimal_idx]\n",
        "\n",
        "def validate_classifiers(classifiers, X_train, y_train, X_test, y_test):\n",
        "    for name, clf in classifiers.items():\n",
        "        print('Validation for {0}'.format(name))\n",
        "        pipeline_clf = make_pipeline(preprocessing.StandardScaler(), clf)\n",
        "        pipeline_clf.fit(X_train, y_train)\n",
        "        metrics.plot_roc_curve(pipeline_clf, X_test, y_test)\n",
        "        churn_probas = pipeline_clf.predict_proba(X_test)[:, 1]\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(y_test, churn_probas)\n",
        "        youden_score = youden(fpr, tpr, thresholds)\n",
        "        print('Youden spot ---> {0}'.format(youden_score))\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "hdg-VogFbZmI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}