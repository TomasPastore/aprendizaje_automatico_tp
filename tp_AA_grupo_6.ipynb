{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomasPastore/aprendizaje_automatico_tp/blob/main/tp_AA_grupo_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import timeit\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "2B-2tXYZSL3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lectura del dataset"
      ],
      "metadata": {
        "id": "Wve0SoH6-upT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn7Ktz_1R0zw"
      },
      "outputs": [],
      "source": [
        "url = 'https://raw.githubusercontent.com/aprendizaje-automatico-dc-uba-ar/material/main/tp/01_aprendizaje_supervisado/datos/minions_publicos.csv'\n",
        "minions_dataset = pd.read_csv(url)\n",
        "\n",
        "y = minions_dataset.iloc[:,-1:]\n",
        "print(y[y[\"target\"] == 1])\n",
        "\n",
        "del minions_dataset[minions_dataset.columns[-1]]\n",
        "print(\"\\n Features\")\n",
        "minions_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto nos indica que hay 154 de clase positiva y el resto de clase negativa. Es decir, está desbalanceado en aproximadamente 30/70. Tenemos que tener en cuenta entonces esto a la hora de splitear los datos."
      ],
      "metadata": {
        "id": "5eX-IzBzwcaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Separación de datos\n",
        "\n",
        "Para la separación de datos de evaluación, lo primero que tuvimos en cuenta fue evaluar la distribucion de etiquetas de los minions entrevistados. Al revisar esto notamos que hay un desbalance entre minions que fueron aceptados vs aquellos que no (aproximadamente fueron aceptados el 30% de los postulantes). Por lo tanto es primordial que mantengamos la proporción entre estas dos clases cuando hagamos los _k-folds_, ya que de no realizarlo nuestro predictor no se entrenaría con las proporciones correctas de los datos. \n",
        "\n",
        "En segundo lugar tenemos que tener en cuenta la cantidad de candidatos que tenemos. Solamente 500 postulados resulta una base de datos más bien reducida, por lo que no tenemos margen a la hora de decidir nuestra estrategia a la hora de separación de datos. Lo que nuestro grupo propone es realizar una separación del 10% para utilizar en la etapa de evaluación final, manteniendo el 90% restante para el desarrollo de nuestros modelos (todo esto haciendo _stratified split_ para que el desbalance de datos no nos perjudique a futuro).\n",
        "\n",
        "#########################\n",
        "Revisar juntos, cuando hacemos el train_test_split se elije al azar, se mantiene las proporciones de las clases pero se hace al azar, no estamos considerando el desbalanceo. mas datos para eval??"
      ],
      "metadata": {
        "id": "mxZBE44sBV78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_dev, X_eval, y_dev, y_eval = train_test_split(minions_dataset, y, shuffle=True, random_state=4, test_size=0.1) # quedan 15 positivos para eval\n",
        "\n",
        "print(f\"X_train dimensión: {X_dev.shape}\")\n",
        "print(f\"y_train dimensión: {y_dev.shape}\")\n",
        "\n",
        "print(f\"X_test dimensión: {X_eval.shape}\")\n",
        "print(f\"y_test dimensión: {y_eval.shape}\")\n"
      ],
      "metadata": {
        "id": "nd48vRPt3KU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Construcción de modelos"
      ],
      "metadata": {
        "id": "6G3jEonGDxuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1) Árbol default con max_height 3"
      ],
      "metadata": {
        "id": "PGUSW2t3UCF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "arbol_gini_3 = DecisionTreeClassifier(max_depth=3)"
      ],
      "metadata": {
        "id": "qPq5DoemUCbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2) Iteradores de cross validation"
      ],
      "metadata": {
        "id": "4aIzNpJyNPZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
        "\n",
        "# consultamos y podemos usar stratifieldk fold, sacaria el otro creo para no complejizar pero eventualmente podriamos comparar los.\n",
        "# evaluar que tanto conviene entrenar balanceado vs entrenar con las proporciones reales.\n",
        "balanced_k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Validar si podemos usar esto porque el enunciado dice k fold\n",
        "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=4)\n",
        "\n",
        "X_train_cv = []\n",
        "y_train_cv = []\n",
        "X_test_cv = []\n",
        "y_test_cv = []\n",
        "\n",
        "for train_index, test_index in sss.split(X_dev, y_dev):\n",
        "    X_train = X_dev.iloc[train_index]\n",
        "    X_test = X_dev.iloc[test_index]\n",
        "    y_train = y_dev.iloc[train_index]\n",
        "    y_test = y_dev.iloc[test_index]\n",
        "    \n",
        "    X_train_cv.append(X_train)\n",
        "    X_test_cv.append(X_test)\n",
        "    y_train_cv.append(y_train)\n",
        "    y_test_cv.append(y_test)\n"
      ],
      "metadata": {
        "id": "LVHBdOaASR73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2) Métricas"
      ],
      "metadata": {
        "id": "EnSjS6fiQi3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Scoring metrics\n",
        "\n",
        "def tn(y, y_pred): return metrics.confusion_matrix(y, y_pred)[0, 0];\n",
        "def fp(y, y_pred): return metrics.confusion_matrix(y, y_pred)[0, 1];\n",
        "def fn(y, y_pred): return metrics.confusion_matrix(y, y_pred)[1, 0];\n",
        "def tp(y, y_pred): return metrics.confusion_matrix(y, y_pred)[1, 1];\n",
        "def specificity(y, y_pred): return tn(y, y_pred)/(tn(y, y_pred) + fp(y,y_pred));\n",
        "def precision(y, y_pred): return tp(y, y_pred)/(tp(y, y_pred) + fp(y, y_pred));\n",
        "def recall(y, y_pred): return tp(y, y_pred)/(tp(y, y_pred) + fn(y, y_pred));\n",
        "def f1(y, y_pred): return 2 * precision(y, y_pred) * recall(y, y_pred) / (precision(y, y_pred) + recall(y_pred))\n",
        "def accuracy(y,y_pred): return metrics.accuracy_score(y, y_pred) # creo q se puede borrar, ver q no se use\n",
        "\n",
        "scoring = {#'precision': metrics.make_scorer(precision), \n",
        "           #'recall': metrics.make_scorer(recall),\n",
        "           #'specificity': metrics.make_scorer(specificity),\n",
        "           #'tp': metrics.make_scorer(tp),\n",
        "           #'tn': metrics.make_scorer(tn),\n",
        "           #'fp': metrics.make_scorer(fp),\n",
        "           #'fn': metrics.make_scorer(fn),\n",
        "           #'f1_score': metrics.make_scorer(f1),\n",
        "           'roc_auc': metrics.make_scorer(metrics.roc_auc_score, needs_proba=True),\n",
        "           'accuracy': metrics.make_scorer(metrics.accuracy_score)\n",
        "           }\n"
      ],
      "metadata": {
        "id": "SBOIPn3sQ97s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2) Árbol default (gini) altura 3 + Crossvalidation K=5 + Accuracy y AUC \n",
        "\n",
        "Integramos las 3 celdas anteriores para correr los folds y calcular las metricas para un classificador"
      ],
      "metadata": {
        "id": "Mkv4DgcVNa19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Crossvalidation with one fixed configuration of hyperparameters.\n",
        "# scoring is a dictionary with the metrics we want to calculate\n",
        "# cv is a cross validation iterator\n",
        "\n",
        "def cross_validate_uba(clf, X, y, scoring, cv, score_train=True):\n",
        "    n = len(y)\n",
        "    k = cv.n_splits\n",
        "\n",
        "    train_global_preds = np.zeros( (n, k-1), dtype=np.ndarray) # train samples will be scored k-1 times\n",
        "    train_global_probas = np.zeros((n, k-1), dtype=np.ndarray)  # we will save only the proba of POSITIVE class\n",
        "    test_global_preds = np.zeros(n)\n",
        "    test_global_probas = np.zeros(n)\n",
        "    \n",
        "    cv_results = dict(train_global_preds=train_global_preds,\n",
        "                      train_global_probas=train_global_probas,\n",
        "                      train_folds_accuracy=np.empty(0),\n",
        "                      train_folds_auc=np.empty(0), \n",
        "                      test_global_preds=test_global_preds,\n",
        "                      test_global_probas=test_global_probas,\n",
        "                      test_folds_accuracy=np.empty(0),\n",
        "                      test_folds_auc=np.empty(0),\n",
        "                      ) \n",
        "\n",
        "    for fold_idx, (train_idxs, test_idxs) in enumerate(cv.split(X, y)):\n",
        "        X_train = X[train_idxs]\n",
        "        y_train = y[train_idxs]\n",
        "        X_test = X[test_idxs]\n",
        "        y_test = y[test_idxs]\n",
        "      \n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        if score_train:\n",
        "            # Scores sobre train\n",
        "            y_pred_train = clf.predict(X_train)\n",
        "            y_proba_train = clf.predict_proba(X_train)\n",
        "            cv_results[\"train_global_preds\"][train_idxs, fold_idx] = y_pred_train \n",
        "            cv_results[\"train_global_probas\"][train_idxs, fold_idx] = y_proba_train\n",
        "\n",
        "        # Scores sobre test\n",
        "        y_pred_test = clf.predict(X_test)\n",
        "        y_proba_test = clf.predict_proba(X_test)\n",
        "        cv_results[\"test_global_preds\"][test_idxs] = y_pred_test\n",
        "        cv_results[\"test_global_accuracy\"][test_idxs] = y_proba_test\n",
        "    \n",
        "\n",
        "    return cv_results\n",
        "\n",
        "\n",
        "def cv_with_metrics(classifier_to_train, X, y, scoring, cv, score_train=False):\n",
        "    models_to_standarize = {'Knn', 'SVM'}\n",
        "    if classifier_to_train.__name__ in models_to_standarize:\n",
        "      clf = make_pipeline(preprocessing.StandardScaler(), clf)\n",
        "    else: \n",
        "      clf = classifier_to_train\n",
        "\n",
        "    cv_results = cross_validate_uba(clf, X, y=y, scoring=scoring, cv=cv, score_train=score_train)\n",
        "\n",
        "    print(f'Crossvalidation metrics for {clf}...\\n')\n",
        "    \n",
        "    # Ver si tiene sentido usar repeated k fold para calcular intervalos de confianza de las metricas\n",
        "\n",
        "    if score_train:\n",
        "      print(f\"\"\"Accuracy [TRAIN]:\n",
        "                \\tGlobal --> {cv_results['train_global_accuracy']:.3f}\\n\n",
        "                \\tFolds: \n",
        "                \\ttRaw --> {list(map(lambda x: round(x, 3), cv_results['train_folds_accuracy']))}\\n\n",
        "                \\t\\tMean --> {np.mean(cv_results['train_folds_accuracy']):.3f}\\n\n",
        "                \\t\\tSTD --> {np.std(cv_results['train_folds_accuracy']):.3f}\\n \n",
        "                \\t\\tMedian --> {np.median(cv_results['train_folds_accuracy']):.3f}\"\"\")\n",
        "\n",
        "    print(f\"\"\"Accuracy [TEST]:\n",
        "          \\tGlobal --> {cv_results['test_global_accuracy']:.3f}\\n\n",
        "          \\tFolds: \n",
        "          \\ttRaw --> {list(map(lambda x: round(x, 3), cv_results['test_folds_accuracy']))}\\n\n",
        "          \\t\\tMean --> {np.mean(cv_results['test_folds_accuracy']):.3f}\\n\n",
        "          \\t\\tSTD --> {np.std(cv_results['test_folds_accuracy']):.3f}\\n \n",
        "          \\t\\tMedian --> {np.median(cv_results['test_folds_accuracy']):.3f}\"\"\")\n",
        "\n",
        "    if score_train:\n",
        "      print(f\"\"\"AUC:\n",
        "                \\tGlobal --> {cv_results['train_global_auc']:.3f}\\n\n",
        "                \\tFolds: \n",
        "                \\ttRaw --> {list(map(lambda x: round(x, 3), cv_results['train_folds_auc']))}\\n\n",
        "                \\t\\tMean --> {np.mean(cv_results['train_folds_auc']):.3f}\\n\n",
        "                \\t\\tSTD --> {np.std(cv_results['train_folds_auc']):.3f}\\n \n",
        "                \\t\\tMedian --> {np.median(cv_results['train_folds_auc']):.3f}\"\"\")\n",
        "      \n",
        "    print(f\"\"\"AUC:\n",
        "              \\tGlobal --> {cv_results['train_global_auc']:.3f}\\n\n",
        "              \\tFolds: \n",
        "              \\ttRaw --> {list(map(lambda x: round(x, 3), cv_results['train_folds_auc']))}\\n\n",
        "              \\t\\tMean --> {np.mean(cv_results['train_folds_auc']):.3f}\\n\n",
        "              \\t\\tSTD --> {np.std(cv_results['train_folds_auc']):.3f}\\n \n",
        "              \\t\\tMedian --> {np.median(cv_results['train_folds_auc']):.3f}\"\"\")\n"
      ],
      "metadata": {
        "id": "2DNwIAfmZ-Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.zeros((10, 5), dtype=np.ndarray)\n",
        "\n",
        "arr[[0,2,4,6,8],3] = [1,2,3,4,5]\n",
        "arr\n",
        "\n"
      ],
      "metadata": {
        "id": "piOGuSOFY-6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"# Corremos el K fold cross validation para una configuracion fija\n",
        "cv_with_metrics(arbol_gini_3, X_dev, y_dev, scoring, cv=balanced_k_fold, train_score=True)"
      ],
      "metadata": {
        "id": "ayhgyzQjQUNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados\n",
        "\n",
        "<table>\n",
        "      <thead>\n",
        "      <tr>\n",
        "      <th align=\"center\">Permutación</th>\n",
        "      <th>Accuracy (training)</th>\n",
        "      <th>Accuracy (validación)</th>\n",
        "      <th>AUC ROC (training)</th>\n",
        "      <th>AUC ROC (validación)</th>\n",
        "      </tr>\n",
        "      </thead>\n",
        "      <tbody>\n",
        "      <tr>\n",
        "      <td align=\"center\">1</td>\n",
        "      <td>0,769</td>\n",
        "      <td>0.722</td>\n",
        "      <td>0.815</td>\n",
        "      <td>0.759</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">2</td>\n",
        "      <td>0.806</td>\n",
        "      <td>0.667</td>\n",
        "      <td>0.774</td>\n",
        "      <td>0.622</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">3</td>\n",
        "      <td>0.841</td>\n",
        "      <td>0.689</td>\n",
        "      <td>0.837</td>\n",
        "      <td>0.614</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">4</td>\n",
        "      <td>0.786</td>\n",
        "      <td>0.6</td>\n",
        "      <td>0.757</td>\n",
        "      <td>0.493</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">5</td>\n",
        "      <td>0.839</td>\n",
        "      <td>0.711</td>\n",
        "      <td>0.841</td>\n",
        "      <td>0.655</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">Global</td>\n",
        "      <td>0.678</td>\n",
        "      <td>0.808</td>\n",
        "      <td>0.817</td>\n",
        "      <td>0.629</td>\n",
        "      </tr>\n",
        "      </tbody>\n",
        "      </table>"
      ],
      "metadata": {
        "id": "CurMQznvQmTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.3) Parameter grid sobre el arbol"
      ],
      "metadata": {
        "id": "tTETHVB8NoEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "def parameter_grid_search(classifier, grid):\n",
        "    param_grid = ParameterGrid(grid)\n",
        "    for config in param_grid:\n",
        "        classifier.set_params(**config)\n",
        "        cv_with_metrics(classifier, X_dev, y_dev, scoring, cv=balanced_k_fold)\n"
      ],
      "metadata": {
        "id": "lIGbkdVsVkLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_arbol = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 3, 5]\n",
        "}\n",
        "parameter_grid_search(classifier=arbol_gini_3, grid=grid_arbol)"
      ],
      "metadata": {
        "id": "_imcGczrQLZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados\n",
        "\n",
        "<table>\n",
        "   <thead>\n",
        "   <tr>\n",
        "   <th align=\"center\">Altura máxima</th>\n",
        "   <th align=\"center\">Criterio de corte</th>\n",
        "   <th>Accuracy (training)</th>\n",
        "   <th>Accuracy (validación)</th>\n",
        "   </tr>\n",
        "   </thead>\n",
        "   <tbody><tr>\n",
        "   <td align=\"center\">3</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td>0.8</td>\n",
        "   <td>0.67</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">5</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td>0.91</td>\n",
        "   <td>0.67</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">Infinito</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td>1.0</td>\n",
        "   <td>0.67</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">3</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td>0.78</td>\n",
        "   <td>0.64</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">5</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td>0.89</td>\n",
        "   <td>0.64</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">Infinito</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td>1.0</td>\n",
        "   <td>0.63</td>\n",
        "   </tr>\n",
        "   </tbody></table>"
      ],
      "metadata": {
        "id": "ssG-8zVoWeom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2 y 2.3) v0"
      ],
      "metadata": {
        "id": "GCCIb5S2OQ4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "BBB = 0\n",
        "CCC = 0\n",
        "DDD = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier(max_depth=3)\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  y_pred_test = arbol.predict(X_train_cv[i])\n",
        "  y_pred_cv.append(y_pred_test)\n",
        "\n",
        "  # print(y_pred)\n",
        "\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el train set: {arbol.score(X_train_cv[i], y_train_cv[i])}\")\n",
        "\n",
        "\n",
        "  # REVISAR, creo que estan al reves los parametros https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score\n",
        "  # y que hay que usarla con predict_proba \n",
        "  auc_train = roc_auc_score(y_pred_test, y_train_cv[i])\n",
        "  print(\"AUC de la curva ROC sobre el train set:\", auc_train)\n",
        "\n",
        "\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  auc_test = roc_auc_score(y_pred, y_test_cv[i])\n",
        "  print(\"AUC de la curva ROC sobre el test set:\", auc_test)\n",
        "\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  BBB += auc_test\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "  DDD += auc_train\n",
        "\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"AUC promedio de test:\", BBB/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)\n",
        "print(\"AUC promedio de train:\", DDD/5)\n",
        "\n"
      ],
      "metadata": {
        "id": "zrk7My-dVtKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resultados**<table>\n",
        "      <thead>\n",
        "      <tr>\n",
        "      <th align=\"center\">Permutación</th>\n",
        "      <th>Accuracy (training)</th>\n",
        "      <th>Accuracy (validación)</th>\n",
        "      <th>AUC ROC (training)</th>\n",
        "      <th>AUC ROC (validación)</th>\n",
        "      </tr>\n",
        "      </thead>\n",
        "      <tbody>\n",
        "      <tr>\n",
        "      <td align=\"center\">1</td>\n",
        "      <td>0,769</td>\n",
        "      <td>0.722</td>\n",
        "      <td>0.815</td>\n",
        "      <td>0.759</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">2</td>\n",
        "      <td>0.806</td>\n",
        "      <td>0.667</td>\n",
        "      <td>0.774</td>\n",
        "      <td>0.622</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">3</td>\n",
        "      <td>0.841</td>\n",
        "      <td>0.689</td>\n",
        "      <td>0.837</td>\n",
        "      <td>0.614</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">4</td>\n",
        "      <td>0.786</td>\n",
        "      <td>0.6</td>\n",
        "      <td>0.757</td>\n",
        "      <td>0.493</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">5</td>\n",
        "      <td>0.839</td>\n",
        "      <td>0.711</td>\n",
        "      <td>0.841</td>\n",
        "      <td>0.655</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "      <td align=\"center\">Global</td>\n",
        "      <td>0.678</td>\n",
        "      <td>0.808</td>\n",
        "      <td>0.817</td>\n",
        "      <td>0.629</td>\n",
        "      </tr>\n",
        "      </tbody>\n",
        "      </table>"
      ],
      "metadata": {
        "id": "BBP2U-1wV0fC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "CCC = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier(max_depth=5)\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  # print(y_pred)\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)"
      ],
      "metadata": {
        "id": "4Dl6YZHaM0bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "CCC = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier()\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  # print(y_pred)\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)"
      ],
      "metadata": {
        "id": "aZZobgYrVVJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "CCC = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  # print(y_pred)\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)"
      ],
      "metadata": {
        "id": "zPswfptgWRj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "CCC = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  # print(y_pred)\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)"
      ],
      "metadata": {
        "id": "i7MCZrIuWRsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arboles_cv = []\n",
        "y_pred_cv = []\n",
        "AAA = 0\n",
        "CCC = 0\n",
        "\n",
        "for i in range(5):\n",
        "  arbol = DecisionTreeClassifier(criterion='entropy')\n",
        "  arbol.fit(X_train_cv[i], y_train_cv[i])\n",
        "  arboles_cv.append(arbol)\n",
        "\n",
        "  # predecimos los valores para las instacias que no vimos\n",
        "  y_pred = arbol.predict(X_test_cv[i])\n",
        "  y_pred_cv.append(y_pred)\n",
        "  # print(y_pred)\n",
        "\n",
        "  #print(f\"Accuracy sobre el test set: {np.mean(y_pred == y_eval)}\") \n",
        "  print(f\"Accuracy sobre el test set: {arbol.score(X_test_cv[i], y_test_cv[i])}\")\n",
        "\n",
        "  AAA += arbol.score(X_test_cv[i], y_test_cv[i])\n",
        "  CCC += arbol.score(X_train_cv[i], y_train_cv[i])\n",
        "\n",
        "print(\"accuracy promedio de test:\", AAA/5)\n",
        "print(\"accuracy promedio de train:\", CCC/5)"
      ],
      "metadata": {
        "id": "Ju7mq4bFWRyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table>\n",
        "   <thead>\n",
        "   <tr>\n",
        "   <th align=\"center\">Altura máxima</th>\n",
        "   <th align=\"center\">Criterio de corte</th>\n",
        "   <th>Accuracy (training)</th>\n",
        "   <th>Accuracy (validación)</th>\n",
        "   </tr>\n",
        "   </thead>\n",
        "   <tbody><tr>\n",
        "   <td align=\"center\">3</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td>0.8</td>\n",
        "   <td>0.67</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">5</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td>0.91</td>\n",
        "   <td>0.67</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">Infinito</td>\n",
        "   <td align=\"center\">Gini</td>\n",
        "   <td>1.0</td>\n",
        "   <td>0.67</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">3</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td>0.78</td>\n",
        "   <td>0.64</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">5</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td>0.89</td>\n",
        "   <td>0.64</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "   <td align=\"center\">Infinito</td>\n",
        "   <td align=\"center\">Entropía</td>\n",
        "   <td>1.0</td>\n",
        "   <td>0.63</td>\n",
        "   </tr>\n",
        "   </tbody></table>"
      ],
      "metadata": {
        "id": "XKxTFERbc3xQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "conclusiones: (a checkear si estan bien calculadas las métricas, siento que tendrian que dar otra cosa) Podemos observar que un aumento en la altura máxima de los arboles no se condice con una mejora en la performance en la etapa de validacion. Esto se debe a que si los arboles tienen altura infinita van a asegurarse de que podamos clasificar correctamente a todas las instancias de train (por eso accuracy de train aumenta a medida que incrementamos la altura máxima); sin embargo esto nos deja en un claro caso de overfitting, lo cual se evidencia al ver que a pesar de una mejora sustancial en la accuracy de train, la accuracy de validation no solo no mejora sino que empeora. \n",
        "A modo de conclusion podemos afirmar que aumentar la altura maxima de los arboles no solo va a resultar mas costoso computacionalmente sino que va a terminar por empeorar nuestro algoritmo."
      ],
      "metadata": {
        "id": "eFwqE-QFe1XG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Comparación de algoritmos con RandomizedSearchCV\n",
        "\n",
        "Algoritmos a probar:\n",
        "\n",
        "* Árboles de decisión (esto ya lo hicimos recien, buscamos mejores arboles con hiperparametros? Si, aca probamos mas hp)\n",
        "* KNN (k-vecinos más cercanos)\n",
        "* SVM (Support vector machine)\n",
        "* LDA (Linear discriminant analysis)\n",
        "* Naïve Bayes"
      ],
      "metadata": {
        "id": "1TLDbhXIZ4d-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "podemos tomar el test score global como el promedio de cada uno de los folds (esta mal pero no tan mal)"
      ],
      "metadata": {
        "id": "foGFEyu-6NVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "def fine_tune(X, y, classifier, model_name, grid, cv, scoring, objective):\n",
        "    print('\\nFine tuning {0}. Objective: {1}'.format(model_name, objective))\n",
        "\n",
        "    pipeline_clf = Pipeline([\n",
        "        ('scaler', preprocessing.StandardScaler()),\n",
        "        ('clf', classifier)\n",
        "        ])\n",
        "\n",
        "    # agrego lo de standarizar, creo que esto hizo que de un poco peor, ver si lo hacemos o no \n",
        "    random_search = RandomizedSearchCV(estimator=pipeline_clf, param_distributions=grid, n_jobs=-1, cv=cv, scoring=scoring, refit=objective)\n",
        "    random_result = random_search.fit(X, y)\n",
        "    print(\"Best score was : %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
        "    return random_result.best_estimator_\n",
        "      "
      ],
      "metadata": {
        "id": "zcXUzh2UCgGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier  \n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Se iniciailizan default porque despues se van variando los hiperparámetros\n",
        "classifiers_to_test = {\n",
        "    'Árbol de decisión': DecisionTreeClassifier(),\n",
        "    'KNN': KNeighborsClassifier(n_jobs=-1),\n",
        "    'SVM' : SVC(),\n",
        "    'LDA' : LDA(),\n",
        "    'Naïve Bayes': GaussianNB()\n",
        "}\n",
        "\n",
        "grids = dict()\n",
        "\n",
        "grids['Árbol de decisión'] = {\n",
        "    'clf__criterion': ['gini', 'entropy', 'log_loss'],\n",
        "    'clf__splitter': ['best', 'random'],\n",
        "    'clf__max_depth': [None, 10, 50, 100, 150, 200],\n",
        "    'clf__max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "grids['KNN'] = {\n",
        "    'clf__n_neighbors': range(5, 26, 5),\n",
        "    'clf__weights': ['uniform', 'distance'],\n",
        "    'clf__leaf_size': randint(20, 50),\n",
        "    'clf__p': [1, 2]\n",
        "}\n",
        "grids['SVM'] = {\n",
        "    'clf__C': [0.5, 1, 2],\n",
        "    'clf__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'clf__degree': [1, 2, 3]\n",
        "}\n",
        "grids['LDA'] = {\n",
        "    'clf__solver': ['lsqr', 'eigen'],\n",
        "    'clf__shrinkage': [None, 'auto', 0, 0.25, 0.5, 0.75, 1]\n",
        "}\n",
        "grids['Naïve Bayes'] = {\n",
        "    'clf__var_smoothing': uniform(1e-9, 1e-7)\n",
        "}\n",
        "\n",
        "# TODO Ver estos warnings jeje\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "best_classifier = dict()\n",
        "for clf_name, clf in classifiers_to_test.items():\n",
        "    # fine_tune devuelve el estimador con la mejor combinación entre las que se prueban, en el dict guardamos la mejor config para cada algoritmo\n",
        "    best_classifier[clf_name] = fine_tune(X_dev, y_dev, clf, clf_name, grids[clf_name], balanced_k_fold, scoring, objective='roc_auc')\n"
      ],
      "metadata": {
        "id": "ZDZZlMrB_y1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier"
      ],
      "metadata": {
        "id": "WUcjmEoab2tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4) ?"
      ],
      "metadata": {
        "id": "PuAcXdhFOCHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construir un modelo RandomForest con 200 árboles. Explorar para qué sirve el hiperparámetro max_features y cómo afecta a la performance del algoritmo mediante una curva de complejidad. Explicar por qué creen que se dieron los resultados obtenidos. Por último, graficar una curva de aprendizaje sobre los parámetros elegidos para determinar si sería útil o no conseguir más datos."
      ],
      "metadata": {
        "id": "ChWKL8rub2-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "max features = The number of features to consider when looking for the best split // \n",
        "n_estimators = cantidad de árboles "
      ],
      "metadata": {
        "id": "NVzDgA1ob5Pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "randomforest = RandomForestClassifier(n_estimators = 200)"
      ],
      "metadata": {
        "id": "PBS9a02Zaa42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7axBpwPVTE3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yDL1c8O7TMJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# quizas sea util al final\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def youden(fpr, tpr, thresholds):\n",
        "    optimal_idx = np.argmax(tpr - fpr)\n",
        "    return thresholds[optimal_idx]\n",
        "\n",
        "def validate_classifiers(classifiers, X_train, y_train, X_test, y_test):\n",
        "    for name, clf in classifiers.items():\n",
        "        print('Validation for {0}'.format(name))\n",
        "        pipeline_clf = make_pipeline(preprocessing.StandardScaler(), clf)\n",
        "        pipeline_clf.fit(X_train, y_train)\n",
        "        metrics.plot_roc_curve(pipeline_clf, X_test, y_test)\n",
        "        churn_probas = pipeline_clf.predict_proba(X_test)[:, 1]\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(y_test, churn_probas)\n",
        "        youden_score = youden(fpr, tpr, thresholds)\n",
        "        print('Youden spot ---> {0}'.format(youden_score))\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "hdg-VogFbZmI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}